{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ce1398",
   "metadata": {},
   "source": [
    "# 3.- Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835133c8",
   "metadata": {},
   "source": [
    "In this notebook, we focus on the image segmentation model. We will use the U-net model (https://github.com/zhixuhao/unet.git).\n",
    "\n",
    "The U-net model is particularly suitable for this task due to several reasons:\n",
    "\n",
    "1. **Encoder-Decoder Architecture**: U-net has a symmetric architecture with an encoder to capture context and a decoder for precise localization, which makes it highly effective for segmentation tasks.\n",
    "2. **Skip Connections**: These connections between the encoder and decoder help preserve spatial information, which is crucial for accurate segmentation.\n",
    "3. **Data Efficiency**: U-net is designed to work well even with relatively small training datasets, making it ideal for cases where annotated data is limited.\n",
    "4. **Versatility**: It has been successfully applied to various medical and general image segmentation problems, demonstrating its robustness and adaptability.\n",
    "5. **State-of-the-Art Performance**: U-net consistently achieves high performance on benchmark segmentation datasets, often outperforming other models in terms of both accuracy and speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b304a00",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598defa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing and transformation libraries\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Scientific computing and data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "\n",
    "# Machine learning and metrics libraries\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Image analysis libraries\n",
    "from skimage import feature, measure, morphology\n",
    "\n",
    "# PyTorch libraries for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba7686",
   "metadata": {},
   "source": [
    "### Data Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cae0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set path\n",
    "TRAINDIR_IMGS = '../dataset/train/imgs'\n",
    "TRAINDIR_MASKS = '../dataset/train/masks'\n",
    "\n",
    "#Validation set path\n",
    "VALDIR_IMGS  = '../dataset/val/imgs'\n",
    "VALDIR_MASKS  = '../dataset/val/masks'\n",
    "\n",
    "#Test set path\n",
    "TESTDIR_IMGS  = '../dataset/test_2/imgs'\n",
    "TESTDIR_MASKS  = '../dataset/test_2/masks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52faea7",
   "metadata": {},
   "source": [
    "### Dataset Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afffb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with directory paths and an optional transform.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir  # Directory containing images\n",
    "        self.mask_dir = mask_dir    # Directory containing corresponding masks\n",
    "        self.transform = transform  # Optional transform to be applied on a sample\n",
    "        self.images = os.listdir(image_dir)  # List of all image filenames in the directory\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)  # Returns the number of images in the dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            # Constructs the full path for the image and mask\n",
    "            img_path = os.path.join(self.image_dir, self.images[index])\n",
    "            mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".jpg\", \".png\"))\n",
    "\n",
    "            # Reads the image using OpenCV\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Image not found at {img_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Converts image from BGR to RGB\n",
    "\n",
    "            # Reads the mask in grayscale mode\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                raise ValueError(f\"Mask not found at {mask_path}\")\n",
    "            mask = mask.astype(np.float32)  # Converts mask to float32\n",
    "            mask[mask == 255.0] = 1.0  # Converts all mask values of 255 to 1\n",
    "\n",
    "            # Applies transformations if any\n",
    "            if self.transform:\n",
    "                augmentations = self.transform(image=image, mask=mask)\n",
    "                image = augmentations['image']\n",
    "                mask = augmentations['mask']\n",
    "\n",
    "            return image, mask  # Returns the image and mask as a tuple\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for index {index}: {e}\")\n",
    "            # Raise the exception to notify the caller about the error\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55776305",
   "metadata": {},
   "source": [
    "### Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8114046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"../models/unet_checkpoint.pth.tar\"):\n",
    "    \"\"\"\n",
    "    Saves the current state of the model to a file.\n",
    "\n",
    "    Parameters:\n",
    "        state (dict): The state of the model, typically containing model parameters.\n",
    "        filename (str, optional): The filename where the state will be saved. Defaults to \"my_checkpoint.pth.tar\".\n",
    "    \"\"\"\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    \"\"\"\n",
    "    Loads the model state from a checkpoint file.\n",
    "\n",
    "    Parameters:\n",
    "        checkpoint (dict): The checkpoint containing model state as saved previously.\n",
    "        model (torch.nn.Module): The model instance where the state will be loaded.\n",
    "    \"\"\"\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    \n",
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Initializes the random seed for each worker to ensure reproducibility.\n",
    "    The seed is based on the worker ID to ensure different seeds for each worker.\n",
    "    \"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "def get_loaders(train_dir, train_maskdir, val_dir, val_maskdir, test_dir, test_maskdir, batch_size, train_transform, val_transform, test_transform, num_workers=4, pin_memory=True):\n",
    "    \"\"\"\n",
    "    Creates DataLoader objects for the training, validation, and test datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the training dataset and DataLoader\n",
    "    train_ds = RobotDataset(image_dir=train_dir, mask_dir=train_maskdir, transform=train_transform)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory, worker_init_fn=worker_init_fn)\n",
    "\n",
    "    # Initialize the validation dataset and DataLoader\n",
    "    val_ds = RobotDataset(image_dir=val_dir, mask_dir=val_maskdir, transform=val_transform)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory, worker_init_fn=worker_init_fn)\n",
    "    \n",
    "    # Initialize\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Computes the accuracy and Dice score of the model using a given loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader (DataLoader): The DataLoader for the dataset to evaluate.\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        device (str, optional): The device to use for computation. Defaults to \"cuda\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the accuracy and Dice score, both multiplied by 100.\n",
    "    \"\"\"\n",
    "    # Initialize counts for true positives, false positives, true negatives, and false negatives\n",
    "    num_tp = 0\n",
    "    num_fp = 0\n",
    "    num_tn = 0\n",
    "    num_fn = 0\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        # Iterate over batches in the DataLoader\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)  # Move inputs to the specified device\n",
    "            y = y.to(device).unsqueeze(1)  # Move targets to the device and add channel dimension\n",
    "            \n",
    "            # Apply sigmoid to the target to get probabilities\n",
    "            y = torch.sigmoid(y)\n",
    "            # Convert probabilities to binary predictions\n",
    "            y = (y > 0.5).float()\n",
    "            \n",
    "            # Get model predictions and convert to binary\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "\n",
    "            # Update counts\n",
    "            num_tp += (preds * y).sum()\n",
    "            num_tn += ((1 - preds) * (1 - y)).sum()\n",
    "            num_fp += (preds * (1 - y)).sum()\n",
    "            num_fn += ((1 - preds) * y).sum()\n",
    "\n",
    "    # Print the counts for debugging purposes\n",
    "    print(f\"FP: {num_fp}, FN: {num_fn}, TP: {num_tp}, TN: {num_tn}\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (num_tp + num_tn) / (num_tp + num_tn + num_fp + num_fn)\n",
    "    # Calculate Dice score\n",
    "    dice_score = (2 * num_tp) / ((2 * num_tp) + num_fp + num_fn + 1e-8)\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Return accuracy and Dice score, both scaled by 100\n",
    "    return accuracy * 100, dice_score * 100\n",
    "\n",
    "\n",
    "def save_predictions_as_imgs(loader, model, folder=\"saved_images/\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Saves the model's predictions as images for each batch in the loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader (torch.utils.data.DataLoader): The DataLoader to get batches from.\n",
    "        model (torch.nn.Module): The model to generate predictions.\n",
    "        folder (str, optional): The directory where the images will be saved. Defaults to \"saved_images/\".\n",
    "        device (str, optional): The device to use for computation. Defaults to \"cuda\".\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Iterate over batches in the DataLoader\n",
    "    for idx, (x, y) in enumerate(loader):\n",
    "        x = x.to(device=device)  # Move inputs to the specified device\n",
    "        \n",
    "        # Disable gradient computation for efficiency\n",
    "        with torch.no_grad():\n",
    "            # Get model predictions and convert to binary\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        \n",
    "        # Save predictions and ground truth images\n",
    "        torchvision.utils.save_image(preds, os.path.join(folder, f\"pred_{idx}.png\"))\n",
    "        torchvision.utils.save_image(y.unsqueeze(1), os.path.join(folder, f\"{idx}.png\"))\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "    \n",
    "def stats(data, savedir):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation for features in the provided data and save the results to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "        data (list of list of dict): The input data containing lists of dictionaries with feature values.\n",
    "        savedir (str): The directory where the resulting statistics JSON file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the mean and standard deviation for each feature.\n",
    "    \"\"\"\n",
    "    # Extract all possible keys (assuming all features are in every dictionary)\n",
    "    keys = list(data[0][0].keys())\n",
    "    keys.remove('centroid')  # Remove 'centroid' since it's a tuple and not trivial to calculate stats\n",
    "\n",
    "    # Create a dictionary to accumulate values for each feature\n",
    "    features = {key: [] for key in keys}\n",
    "\n",
    "    # Iterate over each sublist of dictionaries and each dictionary to accumulate feature values\n",
    "    for sublist in data:\n",
    "        for dic in sublist:\n",
    "            for key, value in dic.items():\n",
    "                # Omit centroids because they are tuples and it's not trivial to calculate mean and std for tuples\n",
    "                if key != 'centroid':\n",
    "                    features[key].append(value)\n",
    "\n",
    "    # Calculate the mean and standard deviation for each feature\n",
    "    stats_dict = {key: (np.mean(values), np.std(values)) for key, values in features.items()}\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "\n",
    "    # Save the dictionary to a JSON file\n",
    "    with open(os.path.join(savedir, 'feature_stats.json'), 'w') as f:\n",
    "        json.dump(stats_dict, f, indent=4)\n",
    "\n",
    "    return stats_dict\n",
    "\n",
    "\n",
    "def get_pieces_features(mask):\n",
    "    \"\"\"\n",
    "    Given a mask path, returns a dictionary with the features of each piece in the image, including the radius of the circumcircle.\n",
    "\n",
    "    Parameters:\n",
    "        mask (torch.Tensor): The input mask as a PyTorch tensor.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing features of a piece in the mask.\n",
    "    \"\"\"\n",
    "    # Convert the mask from tensor to numpy array and scale to 0-255\n",
    "    mask = mask.numpy().squeeze()\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Threshold the image to ensure only the pieces are in white\n",
    "    _, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find all contours on the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter out very small contours that are likely noise\n",
    "    contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 100]\n",
    "\n",
    "    # Initialize list to hold features of each piece\n",
    "    pieces_features = []\n",
    "\n",
    "    # Process each contour to extract features\n",
    "    for piece_contour in contours:\n",
    "        # Create a mask of the piece\n",
    "        piece_mask = np.zeros_like(mask)\n",
    "        cv2.drawContours(piece_mask, [piece_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        # Calculate eccentricity using fitEllipse if the contour has enough points\n",
    "        if piece_contour.shape[0] >= 5:\n",
    "            (x, y), (MA, ma), angle = cv2.fitEllipse(piece_contour)\n",
    "            eccentricity = np.sqrt(1 - (MA / ma) ** 2)\n",
    "        else:\n",
    "            eccentricity = None\n",
    "\n",
    "        # Calculate centroid using moments\n",
    "        M = cv2.moments(piece_contour)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        centroid = (cx, cy)\n",
    "\n",
    "        # Calculate the radius of the minimum enclosing circle\n",
    "        (x, y), radius = cv2.minEnclosingCircle(piece_contour)\n",
    "\n",
    "        # Compile features into a dictionary\n",
    "        features = {\n",
    "            'eccentricity': eccentricity,\n",
    "            'centroid': centroid,\n",
    "            'radius': radius\n",
    "        }\n",
    "\n",
    "        # Add features of the current piece to the list\n",
    "        pieces_features.append(features)\n",
    "\n",
    "    return pieces_features\n",
    "\n",
    "\n",
    "def save_annotated_image(image, save_path, pieces_features):\n",
    "    \"\"\"\n",
    "    Saves the image to the given path, annotated with the circumcircle and centroid mark for each piece in red for visibility.\n",
    "    Converts grayscale images to RGB before annotation.\n",
    "    \n",
    "    Parameters:\n",
    "        image (numpy array): The image array.\n",
    "        save_path (str): Path to save the annotated image.\n",
    "        pieces_features (list): List of dictionaries containing features of each piece including the radius and centroid.\n",
    "    \"\"\"\n",
    "    # Convert the image from tensor to numpy array and scale to 0-255\n",
    "    image = image.numpy().transpose(1, 2, 0)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert grayscale image to RGB if necessary\n",
    "    if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Annotate each piece\n",
    "    for features in pieces_features:\n",
    "        # Draw the circumcircle in red\n",
    "        cv2.circle(image, (int(features['centroid'][0]), int(features['centroid'][1])), int(features['radius']), (0, 0, 255), 2)\n",
    "        # Draw the centroid as a red 'X'\n",
    "        cv2.drawMarker(image, (int(features['centroid'][0]), int(features['centroid'][1])), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "    \n",
    "    # Save the annotated image\n",
    "    cv2.imwrite(save_path, image)\n",
    "\n",
    "def load_stats(filepath= '../data/calibration_matrixes/feature_stats.json'):\n",
    "    \"\"\"\n",
    "    Load the statistics from a JSON file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        stats = json.load(file)\n",
    "    return stats\n",
    "\n",
    "def filter_pieces(stats_data, pieces_list, std=9):\n",
    "    \"\"\"\n",
    "    Filters pieces based on the statistical data provided.\n",
    "\n",
    "    Parameters:\n",
    "        stats_data (dict): A dictionary with keys as properties and values as (mean, sigma).\n",
    "        pieces_list (list): A list of dictionaries, where each dictionary contains properties of a piece.\n",
    "        std (int, optional): The number of standard deviations to use for filtering. Defaults to 9.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing 'centroid' and 'radius' of valid pieces.\n",
    "    \"\"\"\n",
    "    valid_pieces = []\n",
    "    \n",
    "    # Load statistical data\n",
    "    stats_data = load_stats(stats_data)\n",
    "    \n",
    "    # Iterate over each piece\n",
    "    for piece in pieces_list:\n",
    "        valid = True\n",
    "        \n",
    "        # Check each statistical property\n",
    "        for key, (mean, sigma) in stats_data.items():\n",
    "            if key in piece:  # Only check if the key exists in the piece's data\n",
    "                value = piece[key]\n",
    "                # Validate if the value is within the specified number of standard deviations\n",
    "                if not (mean - std * sigma <= value <= mean + std * sigma):\n",
    "                    valid = False\n",
    "                    break\n",
    "        \n",
    "        if valid:\n",
    "            # If all properties are valid, add the centroid and radius to the valid list\n",
    "            valid_pieces.append({'centroid': piece['centroid'], 'radius': piece['radius']})\n",
    "    \n",
    "    return valid_pieces\n",
    "\n",
    "def postprocess(tensor_prediction, area_threshold):\n",
    "    \"\"\"\n",
    "    Post-processes the tensor prediction to apply morphological operations, contour detection, and watershed segmentation.\n",
    "\n",
    "    Parameters:\n",
    "        tensor_prediction (torch.Tensor): The input tensor prediction.\n",
    "        area_threshold (float): The minimum area threshold to filter contours.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The final processed mask as a tensor.\n",
    "    \"\"\"\n",
    "    # Convert tensor to numpy array\n",
    "    image = tensor_prediction.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Ensure the image is in 8-bit format\n",
    "    if image.dtype != np.uint8:\n",
    "        image = np.clip(image * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Handle color conversion if necessary\n",
    "    if len(image.shape) == 2:  # It's a grayscale image\n",
    "        image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        image_color = image  # It's already a BGR image\n",
    "\n",
    "    # Define the kernel for morphological operations\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # Apply morphological opening and closing to reduce noise\n",
    "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Convert to binary image for contour detection\n",
    "    _, binary = cv2.threshold(closing, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # Filter and draw contours by area\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > area_threshold:\n",
    "            cv2.drawContours(mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Further morphological cleaning\n",
    "    sure_bg = cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "    # Distance transformation for foreground segmentation\n",
    "    dist_transform = cv2.distanceTransform(sure_bg, cv2.DIST_L2, 5)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "    # Determine unknown region\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Connected components to separate different objects\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    # Apply the watershed algorithm to segment connected parts\n",
    "    cv2.watershed(image_color, markers)\n",
    "    image_color[markers == -1] = [255, 0, 0]  # Mark boundaries in red\n",
    "\n",
    "    # Prepare the final mask in the same format as the input\n",
    "    final_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    final_mask[markers > 1] = 1\n",
    "    \n",
    "    # Convert final mask back to tensor format\n",
    "    final_tensor = torch.from_numpy(final_mask).unsqueeze(0)  # Add batch dimension if necessary\n",
    "\n",
    "    return final_tensor\n",
    "\n",
    "def read_labels(labels_path):\n",
    "    \"\"\"\n",
    "    Reads a single line of integer labels from a file and converts them into a numpy array.\n",
    "\n",
    "    Parameters:\n",
    "        labels_path (str): The path to the file containing the labels.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of integer labels.\n",
    "    \"\"\"\n",
    "    # Open the file and read the first line\n",
    "    with open(labels_path, 'r') as file:\n",
    "        line = file.readline().strip()  # Read and strip any surrounding whitespace\n",
    "        values = np.array(list(map(int, line.split())))  # Convert the line to a list of integers and then to a numpy array\n",
    "    return values\n",
    "\n",
    "def calculate_corrections(differences):\n",
    "    \"\"\"\n",
    "    Calculates the average corrections in the x and y directions based on the provided differences.\n",
    "\n",
    "    Parameters:\n",
    "        differences (list of tuples): A list of (dx, dy) tuples representing differences.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple (C_x, C_y) representing the average correction in x and y directions.\n",
    "    \"\"\"\n",
    "    # Calculate the total differences in the x and y directions\n",
    "    total_diff_x = sum(diff[0] for diff in differences)\n",
    "    total_diff_y = sum(diff[1] for diff in differences)\n",
    "    \n",
    "    # Count the number of differences\n",
    "    count = len(differences)\n",
    "    \n",
    "    # Calculate the average correction in x and y directions\n",
    "    C_x = total_diff_x / count\n",
    "    C_y = total_diff_y / count\n",
    "    \n",
    "    return C_x, C_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a082d",
   "metadata": {},
   "source": [
    "## 3.1  Definition of the U-Net Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99241a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A module to perform two consecutive convolution operations followed by batch normalization and ReLU activation.\n",
    "\n",
    "    Attributes:\n",
    "        conv (nn.Sequential): A sequential container of two convolutional blocks.\n",
    "\n",
    "    Parameters:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the computation performed at every call of the DoubleConv module.\n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output data after passing through the convolution blocks.\n",
    "        \"\"\"\n",
    "        return self.conv(x)\n",
    "class UNET(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net architecture for image segmentation tasks.\n",
    "\n",
    "    Attributes:\n",
    "        ups (nn.ModuleList): List of modules used in the decoder path of U-Net.\n",
    "        downs (nn.ModuleList): List of modules used in the encoder path of U-Net.\n",
    "        pool (nn.MaxPool2d): Max pooling layer.\n",
    "        bottleneck (DoubleConv): The bottleneck layer of U-Net.\n",
    "        final_conv (nn.Conv2d): Final convolutional layer to produce the output segmentation map.\n",
    "\n",
    "    Parameters:\n",
    "        in_channels (int): Number of channels in the input image.\n",
    "        out_channels (int): Number of channels in the output image.\n",
    "        features (List[int]): Number of features in each layer of the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the U-Net using skip connections and up-sampling.\n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input tensor for the U-Net model.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after processing through U-Net.\n",
    "        \"\"\"\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a585fbc2",
   "metadata": {},
   "source": [
    "## 3.2 Training the U-Net model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0489da",
   "metadata": {},
   "source": [
    "### 3.2.1 Hyperparameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bca5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 50\n",
    "NUM_WORKERS = 0\n",
    "IMAGE_HEIGHT = 270 #135,270,540,1080\n",
    "IMAGE_WIDTH = 480  #240,480,960,1920\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "RUN_NAME = \"u_net\"\n",
    "\n",
    "#EARLY STOPPING\n",
    "BEST_ACCURACY = 0.0\n",
    "BEST_DICE_SCORE = 0.0\n",
    "PATIENCE=10\n",
    "PATIENCE_COUNTER=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc570c",
   "metadata": {},
   "source": [
    "### 3.2.2 Definition of the Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bff6e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"runs/{RUN_NAME}\")\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler, epoch, writer):\n",
    "    loop = tqdm(loader)  # Initialize a tqdm progress bar for the data loader\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)  # Move input data to the specified device (e.g., GPU)\n",
    "        targets = targets.float().unsqueeze(1).to(device=DEVICE)  # Convert targets to float and adjust dimensions\n",
    "        targets = torch.sigmoid(targets)  # Apply sigmoid activation to targets\n",
    "\n",
    "        # Forward pass with automatic mixed precision for efficiency\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)  # Generate model predictions\n",
    "            predictions = torch.sigmoid(predictions)  # Apply sigmoid activation to predictions\n",
    "            loss = loss_fn(predictions, targets)  # Compute the loss\n",
    "\n",
    "        # Log the training loss to TensorBoard\n",
    "        writer.add_scalar(\"Training loss\", loss.item(), epoch * len(loader) + batch_idx)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        scaler.scale(loss).backward()  # Backpropagate the scaled loss\n",
    "        scaler.step(optimizer)  # Update the model parameters\n",
    "        scaler.update()  # Update the scaler for the next iteration\n",
    "\n",
    "        # Update the tqdm progress bar with the current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Compute loss for the epoch and log it (Note: Recompute the loss on the last batch)\n",
    "    loss_epoch = loss_fn(predictions, targets)\n",
    "    writer = SummaryWriter(f\"runs/{RUN_NAME}\")  # Initialize a new SummaryWriter for logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a5f64",
   "metadata": {},
   "source": [
    "### 3.2.3 Definition of the Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7008b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=max(IMAGE_HEIGHT, IMAGE_WIDTH), always_apply=True),  # Resize the image so its smaller side is equal to the max size\n",
    "        A.CenterCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True),       # Crop the center of the image to the given dimensions\n",
    "        A.PadIfNeeded(min_height=IMAGE_HEIGHT, min_width=IMAGE_WIDTH, border_mode=cv2.BORDER_CONSTANT, value=0, always_apply=True),  # Pad the image if needed with a constant border of value 0\n",
    "        A.Rotate(limit=35, p=1.0),  # Rotate the image randomly within the range of -35 to 35 degrees (always applied)\n",
    "        A.HorizontalFlip(p=0.5),    # Flip the image horizontally with 50% probability\n",
    "        A.VerticalFlip(p=0.1),      # Flip the image vertically with 10% probability\n",
    "        A.Normalize(                # Normalize the image to zero mean and unit variance\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),  # Convert the image to a PyTorch tensor\n",
    "    ],\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=max(IMAGE_HEIGHT, IMAGE_WIDTH), always_apply=True),  # Resize the image so its smaller side is equal to the max size\n",
    "        A.CenterCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True),       # Crop the center of the image to the given dimensions\n",
    "        A.PadIfNeeded(min_height=IMAGE_HEIGHT, min_width=IMAGE_WIDTH, border_mode=cv2.BORDER_CONSTANT, value=0, always_apply=True),  # Pad the image if needed with a constant border of value 0\n",
    "        A.Normalize(                # Normalize the image to zero mean and unit variance\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),  # Convert the image to a PyTorch tensor\n",
    "    ],\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True),  # Resize the image to the given dimensions\n",
    "    A.Normalize(                # Normalize the image to zero mean and unit variance\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "    ),\n",
    "    ToTensorV2(),  # Convert the image to a PyTorch tensor\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a94b1",
   "metadata": {},
   "source": [
    "### 3.2.4 Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514fddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization with specified input and output channels\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "# Loss function using Binary Cross Entropy with logits\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "# Optimizer using Adam algorithm\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# Loading datasets for training and validation\n",
    "train_loader, val_loader,test_loader = get_loaders(TRAINDIR_IMGS,TRAINDIR_MASKS,VALDIR_IMGS,VALDIR_MASKS,TESTDIR_IMGS,TESTDIR_MASKS,BATCH_SIZE,train_transform,val_transforms,test_transforms,NUM_WORKERS,PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352b893",
   "metadata": {},
   "source": [
    "### 3.2.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd3f9bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:03<00:00,  1.51it/s, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 133586.0, FN: 5362.0, TP: 263088.0, TN: 26036360.0\n",
      "Epoch 1, New best model with accuracy: 99.4744, Dice Score: 79.1095\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:01<00:00,  1.57it/s, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 9866.0, FN: 7424.0, TP: 261026.0, TN: 26160086.0\n",
      "Epoch 2, New best model with accuracy: 99.9346, Dice Score: 96.7942\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:01<00:00,  1.56it/s, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3550.0, FN: 8900.0, TP: 259550.0, TN: 26166402.0\n",
      "Epoch 3, New best model with accuracy: 99.9529, Dice Score: 97.6578\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:04<00:00,  1.48it/s, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 6387.0, FN: 6519.0, TP: 261931.0, TN: 26163564.0\n",
      "Epoch 4, No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:04<00:00,  1.48it/s, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 5864.0, FN: 7074.0, TP: 261376.0, TN: 26164086.0\n",
      "Epoch 5, No improvement. Patience: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:03<00:00,  1.50it/s, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 15964.0, FN: 10483.0, TP: 257967.0, TN: 26153984.0\n",
      "Epoch 6, No improvement. Patience: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:03<00:00,  1.51it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 6184.0, FN: 6555.0, TP: 261895.0, TN: 26163768.0\n",
      "Epoch 7, No improvement. Patience: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:03<00:00,  1.52it/s, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 5348.0, FN: 6550.0, TP: 261900.0, TN: 26164602.0\n",
      "Epoch 8, New best model with accuracy: 99.9550, Dice Score: 97.7790\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.44it/s, loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 5780.0, FN: 5825.0, TP: 262625.0, TN: 26164168.0\n",
      "Epoch 9, New best model with accuracy: 99.9561, Dice Score: 97.8383\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:03<00:00,  1.51it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 6803.0, FN: 6833.0, TP: 261617.0, TN: 26163152.0\n",
      "Epoch 10, No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:05<00:00,  1.47it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 6394.0, FN: 4832.0, TP: 263618.0, TN: 26163560.0\n",
      "Epoch 11, New best model with accuracy: 99.9575, Dice Score: 97.9152\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:07<00:00,  1.42it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 7207.0, FN: 4261.0, TP: 264189.0, TN: 26162748.0\n",
      "Epoch 12, No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.43it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 5293.0, FN: 6129.0, TP: 262321.0, TN: 26164656.0\n",
      "Epoch 13, No improvement. Patience: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.44it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 5815.0, FN: 4437.0, TP: 264013.0, TN: 26164136.0\n",
      "Epoch 14, New best model with accuracy: 99.9612, Dice Score: 98.0954\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:04<00:00,  1.48it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4783.0, FN: 8061.0, TP: 260389.0, TN: 26165164.0\n",
      "Epoch 15, No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:04<00:00,  1.49it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4371.0, FN: 5706.0, TP: 262744.0, TN: 26165584.0\n",
      "Epoch 16, New best model with accuracy: 99.9619, Dice Score: 98.1184\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:04<00:00,  1.48it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4307.0, FN: 6473.0, TP: 261977.0, TN: 26165644.0\n",
      "Epoch 17, No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:08<00:00,  1.40it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3685.0, FN: 5684.0, TP: 262766.0, TN: 26166266.0\n",
      "Epoch 18, New best model with accuracy: 99.9646, Dice Score: 98.2485\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:07<00:00,  1.41it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4993.0, FN: 5833.0, TP: 262617.0, TN: 26164956.0\n",
      "Epoch 19, No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:05<00:00,  1.46it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4115.0, FN: 5966.0, TP: 262484.0, TN: 26165836.0\n",
      "Epoch 20, No improvement. Patience: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:04<00:00,  1.49it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 5768.0, FN: 3434.0, TP: 265016.0, TN: 26164182.0\n",
      "Epoch 21, New best model with accuracy: 99.9652, Dice Score: 98.2935\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:05<00:00,  1.46it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4067.0, FN: 5628.0, TP: 262822.0, TN: 26165880.0\n",
      "Epoch 22, No improvement. Patience: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:05<00:00,  1.48it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 5644.0, FN: 7492.0, TP: 260958.0, TN: 26164304.0\n",
      "Epoch 23, No improvement. Patience: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:08<00:00,  1.41it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3719.0, FN: 8590.0, TP: 259860.0, TN: 26166232.0\n",
      "Epoch 24, No improvement. Patience: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.44it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 507.0, FN: 32163.0, TP: 236287.0, TN: 26169442.0\n",
      "Epoch 25, No improvement. Patience: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.44it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4110.0, FN: 7178.0, TP: 261272.0, TN: 26165836.0\n",
      "Epoch 26, No improvement. Patience: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:05<00:00,  1.47it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4206.0, FN: 6851.0, TP: 261599.0, TN: 26165742.0\n",
      "Epoch 27, No improvement. Patience: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.44it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4156.0, FN: 6452.0, TP: 261998.0, TN: 26165794.0\n",
      "Epoch 28, No improvement. Patience: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:07<00:00,  1.42it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 4040.0, FN: 7780.0, TP: 260670.0, TN: 26165908.0\n",
      "Epoch 29, No improvement. Patience: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.44it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3140.0, FN: 8300.0, TP: 260150.0, TN: 26166812.0\n",
      "Epoch 30, No improvement. Patience: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:06<00:00,  1.44it/s, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3843.0, FN: 8077.0, TP: 260373.0, TN: 26166108.0\n",
      "Epoch 31, No improvement. Patience: 10/10\n",
      "Early stopping triggered. No improvement in 10 epochs.\n",
      "Best model: Accuracy= 99.9652, Dice_score= 98.2935.\n"
     ]
    }
   ],
   "source": [
    "# Training loop over the number of epochs\n",
    "if False: \n",
    "    # Utility for calculating accuracy\n",
    "    check_accuracy(val_loader, model, device=DEVICE)\n",
    "    # GradScaler for mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Function to handle the training process\n",
    "        train_fn(train_loader, model, optimizer, loss_fn, scaler, epoch, writer)\n",
    "        # Checking model accuracy and dice score after each epoch\n",
    "        accuracy, dice_score = check_accuracy(val_loader, model, device=DEVICE)\n",
    "        # Log accuracy and dice score for each epoch\n",
    "        writer.add_scalar(\"Accuracy\", accuracy, epoch)\n",
    "        writer.add_scalar(\"Dice Score\", dice_score, epoch)\n",
    "        # Check for model improvement, save model if improved\n",
    "        if accuracy > BEST_ACCURACY * 0.8 and dice_score > BEST_DICE_SCORE:\n",
    "            BEST_ACCURACY = accuracy\n",
    "            BEST_DICE_SCORE = dice_score\n",
    "            print(f\"Epoch {epoch + 1}, New best model with accuracy: {accuracy:.4f}, Dice Score: {dice_score:.4f}\")\n",
    "            # Save model checkpoint\n",
    "            checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            save_checkpoint(checkpoint)\n",
    "            PATIENCE_COUNTER = 0  # Reset patience counter\n",
    "        else:\n",
    "            PATIENCE_COUNTER += 1  # Increment patience counter\n",
    "            print(f\"Epoch {epoch + 1}, No improvement. Patience: {PATIENCE_COUNTER}/{PATIENCE}\")\n",
    "        # Early stopping if no improvement for a defined number of epochs\n",
    "        if PATIENCE_COUNTER >= PATIENCE:\n",
    "            print(f\"Early stopping triggered. No improvement in {PATIENCE} epochs.\")\n",
    "            print(f\"Best model: Accuracy= {BEST_ACCURACY:.4f}, Dice_score= {BEST_DICE_SCORE:.4f}.\")\n",
    "            break\n",
    "        # Save sample predictions as images\n",
    "        save_predictions_as_imgs(\n",
    "            val_loader, model, folder=\"results/saved_unet\", device=DEVICE\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517edf2",
   "metadata": {},
   "source": [
    "# 4.- Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757be74",
   "metadata": {},
   "source": [
    "## 4.1 Performance of the segmentation block with different Image Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf0fc2",
   "metadata": {},
   "source": [
    "In this study, we will evaluate the model's performance in terms of dice score, accuracy, and average inference time per image based on the input image size. We will begin by studying the performance with a downscaling factor of 4 (Image Height = 270 and Image Width = 480) and compare it with the model's performance without downscaling (Image Height = 1080, Image Width = 1920)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d39a1",
   "metadata": {},
   "source": [
    "### Image Height = 270 & Image Width=480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc2a54ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "FP: 1581.0, FN: 3.0, TP: 15827.0, TN: 3092989.0\n",
      "Model accuracy: 99.9490737915039\n",
      "Model dice score: 95.23436737060547\n",
      "Average time per image: 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define image dimensions\n",
    "IMAGE_HEIGHT = 270\n",
    "IMAGE_WIDTH = 480\n",
    "\n",
    "# Path to the saved model checkpoint\n",
    "CHECKPOINT_PATH = '../models/unet_checkpoint.pth.tar'\n",
    "\n",
    "# Get data loaders for training, validation, and testing datasets with specified parameters\n",
    "train_loader, val_loader, test_loader = get_loaders(\n",
    "    TRAINDIR_IMGS, TRAINDIR_MASKS, VALDIR_IMGS, VALDIR_MASKS,\n",
    "    TESTDIR_IMGS, TESTDIR_MASKS, BATCH_SIZE, train_transform,\n",
    "    val_transforms, test_transforms, NUM_WORKERS, PIN_MEMORY\n",
    ")\n",
    "\n",
    "# Initialize the UNET model with specified input and output channels\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "\n",
    "# Load the model checkpoint\n",
    "load_checkpoint(torch.load(CHECKPOINT_PATH), model)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Record the start time of processing\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluate the model accuracy and dice score on the test dataset\n",
    "accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "\n",
    "# Record the end time of processing\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total processing time\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Calculate the average processing time per image\n",
    "average_time_per_image = total_time / len(test_loader.dataset)\n",
    "\n",
    "# Print the model accuracy\n",
    "print(f'Model accuracy: {accuracy}')\n",
    "\n",
    "# Print the model dice score\n",
    "print(f'Model dice score: {dice_score}')\n",
    "\n",
    "# Print the average time per image\n",
    "print(f\"Average time per image: {average_time_per_image:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95dc50",
   "metadata": {},
   "source": [
    "### Image Height =1080 & Image Width=1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions\n",
    "IMAGE_HEIGHT = 1080\n",
    "IMAGE_WIDTH = 1920\n",
    "\n",
    "# Path to the saved model checkpoint\n",
    "CHECKPOINT_PATH = '../models/unet_checkpoint.pth.tar'\n",
    "\n",
    "# Get data loaders for training, validation, and testing datasets with specified parameters\n",
    "train_loader, val_loader, test_loader = get_loaders(\n",
    "    TRAINDIR_IMGS, TRAINDIR_MASKS, VALDIR_IMGS, VALDIR_MASKS,\n",
    "    TESTDIR_IMGS, TESTDIR_MASKS, BATCH_SIZE, train_transform,\n",
    "    val_transforms, test_transforms, NUM_WORKERS, PIN_MEMORY\n",
    ")\n",
    "\n",
    "# Initialize the UNET model with specified input and output channels\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "\n",
    "# Load the model checkpoint\n",
    "load_checkpoint(torch.load(CHECKPOINT_PATH), model)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Record the start time of processing\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluate the model accuracy and dice score on the test dataset\n",
    "accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "\n",
    "# Record the end time of processing\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total processing time\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Calculate the average processing time per image\n",
    "average_time_per_image = total_time / len(test_loader.dataset)\n",
    "\n",
    "# Print the model accuracy\n",
    "print(f'Model accuracy: {accuracy}')\n",
    "\n",
    "# Print the model dice score\n",
    "print(f'Model dice score: {dice_score}')\n",
    "\n",
    "# Print the average time per image\n",
    "print(f\"Average time per image: {average_time_per_image:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f50fe",
   "metadata": {},
   "source": [
    "It is observed that the performance is slightly worse when applying the reduced scale. However, the inference time is much lower when using the downscaled images, leading us to conclude that it is advantageous to use this for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3e90e",
   "metadata": {},
   "source": [
    "## 4.2 Performance of the segmentation block with different type of corruptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d963dda",
   "metadata": {},
   "source": [
    "In this second study, we will evaluate the model's performance on the test set with different types of corruptions and severities. The same metrics of accuracy and dice score have been used. The results are presented in the form of a spider plot, as this allows for a quick evaluation of the performance against the different types of corruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd983bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (ups): ModuleList(\n",
       "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downs): ModuleList(\n",
       "    (0): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image dimensions and directory paths\n",
    "IMAGE_HEIGHT = 270  # Height of the images\n",
    "IMAGE_WIDTH = 480  # Width of the images\n",
    "FOLDER = '../dataset/test-C'  # Path to the main dataset folder\n",
    "SEVERITIES = ['s1', 's2', 's3', 's4', 's5']  # List of severity levels for corruptions\n",
    "CORRUPTION = 'c0'  # Corruption type identifier\n",
    "SUBFOLDERS = ['imgs', 'masks']  # Subfolders for images and masks\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'  # Path to save graph results\n",
    "CHECKPOINT_PATH = '../models/unet_checkpoint.pth.tar'  # Path to the model checkpoint file\n",
    "\n",
    "# Define transformations\n",
    "corr_transforms = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True),  # Resize images to specified dimensions\n",
    "    A.Normalize(  # Normalize images to zero mean and unit variance\n",
    "        mean=[0.0, 0.0, 0.0],\n",
    "        std=[1.0, 1.0, 1.0],\n",
    "        max_pixel_value=255.0,\n",
    "    ),\n",
    "    ToTensorV2(),  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "def get_corruption_dataset_loaders(img_dir, mask_dir, batch_size, transform, num_workers=4, pin_memory=True):\n",
    "    \"\"\"Create DataLoader for corrupted dataset.\"\"\"\n",
    "    # Initialize dataset with specified directories and transformations\n",
    "    corr_ds = RobotDataset(image_dir=img_dir, mask_dir=mask_dir, transform=transform)\n",
    "    # Create DataLoader for the dataset with given parameters\n",
    "    corr_loader = DataLoader(corr_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory, worker_init_fn=worker_init_fn)\n",
    "    return corr_loader\n",
    "\n",
    "# Initialize model and load checkpoint\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)  # Create UNET model and move it to the specified device\n",
    "load_checkpoint(torch.load(CHECKPOINT_PATH), model)  # Load the model checkpoint\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edf24169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_plot(dice_scores, graph_savefile, corr_name=None):\n",
    "    os.makedirs(os.path.dirname(graph_savefile), exist_ok=True)  # Create directories if they don't exist\n",
    "    \n",
    "    labels = np.array(SEVERITIES)  # Convert severity levels to a NumPy array\n",
    "    num_vars = len(labels)  # Number of variables (severity levels)\n",
    "    \n",
    "    # Compute angle for each bar\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()  # Equally spaced angles around the circle\n",
    "    \n",
    "    # Close the loop for plotting by appending the start value to the end\n",
    "    dice_scores = np.concatenate((dice_scores, [dice_scores[0]]))  # Append the first dice score to the end\n",
    "    angles += angles[:1]  # Append the first angle to the end\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))  # Create a polar subplot\n",
    "    ax.fill(angles, dice_scores, color='cyan', alpha=0.6)  # Fill the area under the plot\n",
    "    ax.plot(angles, dice_scores, color='blue', linewidth=2)  # Plot the dice scores\n",
    "    \n",
    "    # Set labels for each slice\n",
    "    ax.set_xticks(angles[:-1])  # Set the ticks at each angle (except the last one to avoid duplication)\n",
    "    ax.set_xticklabels(labels, fontsize=14, fontweight='bold', color='navy')  # Set the labels for each tick\n",
    "    \n",
    "    # Set the range for each slice\n",
    "    ax.set_ylim(0, 100)  # Set the y-axis range from 0 to 100\n",
    "    \n",
    "    # Aesthetic improvements\n",
    "    ax.set_facecolor('floralwhite')  # Set background color\n",
    "    ax.grid(color='grey', linestyle='--', linewidth=0.5)  # Customize the grid\n",
    "    \n",
    "    # Set the plot title\n",
    "    title = f'{corr_name} Dice Score Spider Plot' if corr_name else 'Dice Score Spider Plot'\n",
    "    plt.title(title, fontsize=16, fontweight='bold')  # Set the plot title\n",
    "    \n",
    "    plt.savefig(graph_savefile)  # Save the plot to the specified file\n",
    "    plt.close()  # Close the plot to free memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b514bc",
   "metadata": {},
   "source": [
    "### 4.2.1 c=0 Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b6b1e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3721.0, FN: 32.0, TP: 37257.0, TN: 7086990.0\n",
      "The accuracy of s=0 is: 99.94734954833984%\n",
      "The dice_score of s=0 is: 95.20487976074219%\n",
      "FP: 3895.0, FN: 26.0, TP: 37263.0, TN: 7086816.0\n",
      "The accuracy of s=1 is: 99.94499206542969%\n",
      "The dice_score of s=1 is: 95.00172424316406%\n",
      "FP: 12129.0, FN: 31.0, TP: 37258.0, TN: 7078582.0\n",
      "The accuracy of s=2 is: 99.82940673828125%\n",
      "The dice_score of s=2 is: 85.97074127197266%\n",
      "FP: 53162.0, FN: 45.0, TP: 37244.0, TN: 7037549.0\n",
      "The accuracy of s=3 is: 99.25354766845703%\n",
      "The dice_score of s=3 is: 58.33274841308594%\n",
      "FP: 142445.0, FN: 117.0, TP: 37172.0, TN: 6948266.0\n",
      "The accuracy of s=4 is: 97.99996948242188%\n",
      "The dice_score of s=4 is: 34.27475357055664%\n",
      "[95.20487976 95.00172424 85.97074127 58.33274841 34.27475357]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c0'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Gaussian Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4390e",
   "metadata": {},
   "source": [
    "### 4.2.2 c=1 Shot Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8fdc7c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3932.0, FN: 27.0, TP: 37262.0, TN: 7086779.0\n",
      "The accuracy of s=0 is: 99.9444580078125%\n",
      "The dice_score of s=0 is: 94.95559692382812%\n",
      "FP: 5586.0, FN: 26.0, TP: 37263.0, TN: 7085125.0\n",
      "The accuracy of s=1 is: 99.9212646484375%\n",
      "The dice_score of s=1 is: 92.99707794189453%\n",
      "FP: 24288.0, FN: 29.0, TP: 37260.0, TN: 7066423.0\n",
      "The accuracy of s=2 is: 99.65885162353516%\n",
      "The dice_score of s=2 is: 75.39686584472656%\n",
      "FP: 113246.0, FN: 47.0, TP: 37242.0, TN: 6977465.0\n",
      "The accuracy of s=3 is: 98.41059112548828%\n",
      "The dice_score of s=3 is: 39.66619873046875%\n",
      "FP: 230444.0, FN: 86.0, TP: 37203.0, TN: 6860267.0\n",
      "The accuracy of s=4 is: 96.76585388183594%\n",
      "The dice_score of s=4 is: 24.400529861450195%\n",
      "[94.95559692 92.99707794 75.39686584 39.66619873 24.40052986]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c1'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Shot Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce5fb3d",
   "metadata": {},
   "source": [
    "### 4.2.3  c=2 Impulse Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14f35545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3727.0, FN: 24.0, TP: 37265.0, TN: 7086984.0\n",
      "The accuracy of s=0 is: 99.94737243652344%\n",
      "The dice_score of s=0 is: 95.20829010009766%\n",
      "FP: 4145.0, FN: 32.0, TP: 37257.0, TN: 7086566.0\n",
      "The accuracy of s=1 is: 99.94140625%\n",
      "The dice_score of s=1 is: 94.69189453125%\n",
      "FP: 6649.0, FN: 27.0, TP: 37262.0, TN: 7084062.0\n",
      "The accuracy of s=2 is: 99.90634155273438%\n",
      "The dice_score of s=2 is: 91.77832794189453%\n",
      "FP: 28996.0, FN: 40.0, TP: 37249.0, TN: 7061715.0\n",
      "The accuracy of s=3 is: 99.5926513671875%\n",
      "The dice_score of s=3 is: 71.95510864257812%\n",
      "FP: 85043.0, FN: 115.0, TP: 37174.0, TN: 7005668.0\n",
      "The accuracy of s=4 is: 98.80530548095703%\n",
      "The dice_score of s=4 is: 46.611412048339844%\n",
      "[95.2082901  94.69189453 91.77832794 71.95510864 46.61141205]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c2'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Impulse Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed69b04",
   "metadata": {},
   "source": [
    "### 4.2.4  c=4 Glass Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d37c396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 2347.0, FN: 307.0, TP: 36982.0, TN: 7088364.0\n",
      "The accuracy of s=0 is: 99.9627685546875%\n",
      "The dice_score of s=0 is: 96.53606414794922%\n",
      "FP: 1307.0, FN: 1016.0, TP: 36273.0, TN: 7089404.0\n",
      "The accuracy of s=1 is: 99.9674072265625%\n",
      "The dice_score of s=1 is: 96.89724731445312%\n",
      "FP: 727.0, FN: 2160.0, TP: 35129.0, TN: 7089984.0\n",
      "The accuracy of s=2 is: 99.9594955444336%\n",
      "The dice_score of s=2 is: 96.05304718017578%\n",
      "FP: 314.0, FN: 3982.0, TP: 33307.0, TN: 7090397.0\n",
      "The accuracy of s=3 is: 99.93972778320312%\n",
      "The dice_score of s=3 is: 93.94161987304688%\n",
      "FP: 4.0, FN: 36616.0, TP: 673.0, TN: 7090707.0\n",
      "The accuracy of s=4 is: 99.48625183105469%\n",
      "The dice_score of s=4 is: 3.5452771186828613%\n",
      "[96.53606415 96.89724731 96.05304718 93.94161987  3.54527712]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c4'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Glass Blur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3a371",
   "metadata": {},
   "source": [
    "### 4.2.5 c=5 Motion Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "517d3dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 6418.0, FN: 74.0, TP: 37215.0, TN: 7084293.0\n",
      "The accuracy of s=0 is: 99.90892028808594%\n",
      "The dice_score of s=0 is: 91.97746276855469%\n",
      "FP: 10044.0, FN: 54.0, TP: 37235.0, TN: 7080667.0\n",
      "The accuracy of s=1 is: 99.85832977294922%\n",
      "The dice_score of s=1 is: 88.05931091308594%\n",
      "FP: 10044.0, FN: 54.0, TP: 37235.0, TN: 7080667.0\n",
      "The accuracy of s=2 is: 99.85832977294922%\n",
      "The dice_score of s=2 is: 88.05931091308594%\n",
      "FP: 10044.0, FN: 54.0, TP: 37235.0, TN: 7080667.0\n",
      "The accuracy of s=3 is: 99.85832977294922%\n",
      "The dice_score of s=3 is: 88.05931091308594%\n",
      "FP: 13791.0, FN: 84.0, TP: 37205.0, TN: 7076920.0\n",
      "The accuracy of s=4 is: 99.80534362792969%\n",
      "The dice_score of s=4 is: 84.28385162353516%\n",
      "[91.97746277 88.05931091 88.05931091 88.05931091 84.28385162]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c5'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Motion Blur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e12e12b",
   "metadata": {},
   "source": [
    "### 4.2.6 c=6 Fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be2fbbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 991.0, FN: 1434.0, TP: 35855.0, TN: 7089720.0\n",
      "The accuracy of s=0 is: 99.96598052978516%\n",
      "The dice_score of s=0 is: 96.72893524169922%\n",
      "FP: 723.0, FN: 2758.0, TP: 34531.0, TN: 7089988.0\n",
      "The accuracy of s=1 is: 99.95116424560547%\n",
      "The dice_score of s=1 is: 95.20146942138672%\n",
      "FP: 671.0, FN: 4369.0, TP: 32920.0, TN: 7090040.0\n",
      "The accuracy of s=2 is: 99.92929077148438%\n",
      "The dice_score of s=2 is: 92.88938903808594%\n",
      "FP: 710.0, FN: 3937.0, TP: 33352.0, TN: 7090001.0\n",
      "The accuracy of s=3 is: 99.93480682373047%\n",
      "The dice_score of s=3 is: 93.48712921142578%\n",
      "FP: 1172.0, FN: 5504.0, TP: 31785.0, TN: 7089539.0\n",
      "The accuracy of s=4 is: 99.90634155273438%\n",
      "The dice_score of s=4 is: 90.49625396728516%\n",
      "[96.72893524 95.20146942 92.88938904 93.48712921 90.49625397]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c6'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Fog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26f816",
   "metadata": {},
   "source": [
    "### 4.2.7 c=7 Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c736170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3698.0, FN: 32.0, TP: 37257.0, TN: 7087013.0\n",
      "The accuracy of s=0 is: 99.94766998291016%\n",
      "The dice_score of s=0 is: 95.23286437988281%\n",
      "FP: 3823.0, FN: 55.0, TP: 37234.0, TN: 7086888.0\n",
      "The accuracy of s=1 is: 99.94559478759766%\n",
      "The dice_score of s=1 is: 95.05016326904297%\n",
      "FP: 3815.0, FN: 77.0, TP: 37212.0, TN: 7086896.0\n",
      "The accuracy of s=2 is: 99.94539642333984%\n",
      "The dice_score of s=2 is: 95.03038787841797%\n",
      "FP: 3745.0, FN: 108.0, TP: 37181.0, TN: 7086966.0\n",
      "The accuracy of s=3 is: 99.9459457397461%\n",
      "The dice_score of s=3 is: 95.07383728027344%\n",
      "FP: 3674.0, FN: 189.0, TP: 37100.0, TN: 7087037.0\n",
      "The accuracy of s=4 is: 99.94580841064453%\n",
      "The dice_score of s=4 is: 95.05142974853516%\n",
      "[95.23286438 95.05016327 95.03038788 95.07383728 95.05142975]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c7'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Brightness')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1396a",
   "metadata": {},
   "source": [
    "### 4.2.8 c=8 Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e1e6805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 182.0, FN: 3030.0, TP: 34259.0, TN: 7090529.0\n",
      "The accuracy of s=0 is: 99.95494079589844%\n",
      "The dice_score of s=0 is: 95.5220947265625%\n",
      "FP: 0.0, FN: 13010.0, TP: 24279.0, TN: 7090711.0\n",
      "The accuracy of s=1 is: 99.8174819946289%\n",
      "The dice_score of s=1 is: 78.868896484375%\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "The accuracy of s=2 is: 99.47686767578125%\n",
      "The dice_score of s=2 is: 0.0%\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "The accuracy of s=3 is: 99.47686767578125%\n",
      "The dice_score of s=3 is: 0.0%\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "The accuracy of s=4 is: 99.47686767578125%\n",
      "The dice_score of s=4 is: 0.0%\n",
      "[95.52209473 78.86889648  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c8'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Contrast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637650ca",
   "metadata": {},
   "source": [
    "### 4.2.9 c=9 Elastic Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f16216f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 14130.0, FN: 10046.0, TP: 27243.0, TN: 7076581.0\n",
      "The accuracy of s=0 is: 99.66083526611328%\n",
      "The dice_score of s=0 is: 69.26597595214844%\n",
      "FP: 22334.0, FN: 18106.0, TP: 19183.0, TN: 7068377.0\n",
      "The accuracy of s=1 is: 99.43266296386719%\n",
      "The dice_score of s=1 is: 48.684112548828125%\n",
      "FP: 4986.0, FN: 891.0, TP: 36398.0, TN: 7085725.0\n",
      "The accuracy of s=2 is: 99.91754913330078%\n",
      "The dice_score of s=2 is: 92.52983856201172%\n",
      "FP: 4970.0, FN: 1073.0, TP: 36216.0, TN: 7085741.0\n",
      "The accuracy of s=3 is: 99.91522216796875%\n",
      "The dice_score of s=3 is: 92.2994613647461%\n",
      "FP: 5334.0, FN: 1242.0, TP: 36047.0, TN: 7085377.0\n",
      "The accuracy of s=4 is: 99.90774536132812%\n",
      "The dice_score of s=4 is: 91.64102935791016%\n",
      "[69.26597595 48.68411255 92.52983856 92.29946136 91.64102936]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c9'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Elastic Transform')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f1b4f",
   "metadata": {},
   "source": [
    "### 4.2.10 c=11 Speckle Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d442cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3918.0, FN: 22.0, TP: 37267.0, TN: 7086793.0\n",
      "The accuracy of s=0 is: 99.9447250366211%\n",
      "The dice_score of s=0 is: 94.9792251586914%\n",
      "FP: 4104.0, FN: 23.0, TP: 37266.0, TN: 7086607.0\n",
      "The accuracy of s=1 is: 99.94210052490234%\n",
      "The dice_score of s=1 is: 94.75330352783203%\n",
      "FP: 20353.0, FN: 22.0, TP: 37267.0, TN: 7070358.0\n",
      "The accuracy of s=2 is: 99.71415710449219%\n",
      "The dice_score of s=2 is: 78.53206634521484%\n",
      "FP: 50358.0, FN: 25.0, TP: 37264.0, TN: 7040353.0\n",
      "The accuracy of s=3 is: 99.29316711425781%\n",
      "The dice_score of s=3 is: 59.66488265991211%\n",
      "FP: 119343.0, FN: 30.0, TP: 37259.0, TN: 6971368.0\n",
      "The accuracy of s=4 is: 98.3252944946289%\n",
      "The dice_score of s=4 is: 38.43293380737305%\n",
      "[94.97922516 94.75330353 78.53206635 59.66488266 38.43293381]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c11'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Speckle Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a7445",
   "metadata": {},
   "source": [
    "### 4.2.11 c=12 Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1216b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 762.0, FN: 1723.0, TP: 35566.0, TN: 7089949.0\n",
      "The accuracy of s=0 is: 99.96513366699219%\n",
      "The dice_score of s=0 is: 96.62442016601562%\n",
      "FP: 189.0, FN: 36842.0, TP: 447.0, TN: 7090522.0\n",
      "The accuracy of s=1 is: 99.48048400878906%\n",
      "The dice_score of s=1 is: 2.3572840690612793%\n",
      "FP: 102.0, FN: 37191.0, TP: 98.0, TN: 7090609.0\n",
      "The accuracy of s=2 is: 99.476806640625%\n",
      "The dice_score of s=2 is: 0.5228200554847717%\n",
      "FP: 24.0, FN: 37281.0, TP: 8.0, TN: 7090687.0\n",
      "The accuracy of s=3 is: 99.47663879394531%\n",
      "The dice_score of s=3 is: 0.04287130385637283%\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "The accuracy of s=4 is: 99.47686767578125%\n",
      "The dice_score of s=4 is: 0.0%\n",
      "[9.66244202e+01 2.35728407e+00 5.22820055e-01 4.28713039e-02\n",
      " 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c12'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Gaussian Blur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3259bc",
   "metadata": {},
   "source": [
    "### 4.2.12 c=13 spatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23a6eea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3651.0, FN: 27.0, TP: 37262.0, TN: 7087060.0\n",
      "The accuracy of s=0 is: 99.94840240478516%\n",
      "The dice_score of s=0 is: 95.29679107666016%\n",
      "FP: 3284.0, FN: 59.0, TP: 37230.0, TN: 7087427.0\n",
      "The accuracy of s=1 is: 99.9531021118164%\n",
      "The dice_score of s=1 is: 95.7032470703125%\n",
      "FP: 3144.0, FN: 76.0, TP: 37213.0, TN: 7087567.0\n",
      "The accuracy of s=2 is: 99.95482635498047%\n",
      "The dice_score of s=2 is: 95.85297393798828%\n",
      "FP: 221586.0, FN: 18.0, TP: 37271.0, TN: 6869125.0\n",
      "The accuracy of s=3 is: 96.89107513427734%\n",
      "The dice_score of s=3 is: 25.170692443847656%\n",
      "FP: 901342.0, FN: 12.0, TP: 37277.0, TN: 6189369.0\n",
      "The accuracy of s=4 is: 87.35474395751953%\n",
      "The dice_score of s=4 is: 7.6394500732421875%\n",
      "[95.29679108 95.70324707 95.85297394 25.17069244  7.63945007]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c13'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Spatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abe80f",
   "metadata": {},
   "source": [
    "### 4.2.13 c=14 Saturate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b444907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 843.0, FN: 1365.0, TP: 35924.0, TN: 7089868.0\n",
      "The accuracy of s=0 is: 99.96902465820312%\n",
      "The dice_score of s=0 is: 97.01847076416016%\n",
      "FP: 281.0, FN: 36277.0, TP: 1012.0, TN: 7090430.0\n",
      "The accuracy of s=1 is: 99.48712158203125%\n",
      "The dice_score of s=1 is: 5.245969295501709%\n",
      "FP: 5105.0, FN: 5.0, TP: 37284.0, TN: 7085606.0\n",
      "The accuracy of s=2 is: 99.92831420898438%\n",
      "The dice_score of s=2 is: 93.5866928100586%\n",
      "FP: 464228.0, FN: 1.0, TP: 37288.0, TN: 6626483.0\n",
      "The accuracy of s=3 is: 93.48724365234375%\n",
      "The dice_score of s=3 is: 13.8410005569458%\n",
      "FP: 4944049.0, FN: 1.0, TP: 37288.0, TN: 2146662.0\n",
      "The accuracy of s=4 is: 30.639028549194336%\n",
      "The dice_score of s=4 is: 1.485984444618225%\n",
      "[97.01847076  5.2459693  93.58669281 13.84100056  1.48598444]\n"
     ]
    }
   ],
   "source": [
    "CORRUPTION = 'c14'\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Assuming get_corruption_dataset_loaders returns a DataLoader\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Assuming check_accuracy returns accuracy and dice_score\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f'The accuracy of s={i} is: {accuracy}%')\n",
    "    print(f'The dice_score of s={i} is: {dice_score}%')\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "\n",
    "print(dice_scores)\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, GRAPH_SAVEFILE,'Saturate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2518dae",
   "metadata": {},
   "source": [
    "## First Iteration (Modelling & Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549f5df",
   "metadata": {},
   "source": [
    "We notice that the model's performance significantly worsens under severe conditions for some corruptions. At this point, we developed a post-processing block, which will be applied to the segmented images from the U-Net model and will act as a filter to ensure that the minimum number of pixels that do not correspond to a real piece pass to the next block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef1b5b",
   "metadata": {},
   "source": [
    "## 3.3 Postprocessing Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f4040",
   "metadata": {},
   "source": [
    "After evaluating the U-Net model against various levels of perturbations, we consider it beneficial to add a post-processing component to the modeling pipeline. This component will take the output image from the U-Net model and act as a filter to prevent as many pixels that do not correspond to the actual piece from passing to the next block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116ef28",
   "metadata": {},
   "source": [
    "### 3.3.1 Definition of the function to process and plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_plot_image(file_path, area_thresholds):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function process_and_plot_image takes an image file path and a list of area thresholds as input. \n",
    "    It performs image segmentation using morphological operations, contour detection, and the Watershed algorithm. \n",
    "    The function visualizes the segmentation results for different area thresholds, showing how the segmentation \n",
    "    changes as the threshold varies. Each threshold value is used to filter contours based on their area, and the \n",
    "    resulting segmented regions are displayed in a subplot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Convert to color for visualization\n",
    "    image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Define the kernel for morphological operations\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Study of Area Threshold for Image Segmentation')\n",
    "\n",
    "    for idx, area_threshold in enumerate(area_thresholds):\n",
    "        # Perform morphological operations: opening followed by closing\n",
    "        opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Find contours in the processed image\n",
    "        contours, _ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        mask = np.zeros_like(image)\n",
    "\n",
    "        # Filter and draw contours based on area threshold\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > area_threshold:\n",
    "                cv2.drawContours(mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "        # Further morphological operations for background extraction\n",
    "        sure_bg = cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "        # Distance transform and thresholding to find the sure foreground\n",
    "        dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "        _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "        # Identifying unknown region\n",
    "        unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "        # Connected components labeling\n",
    "        _, markers = cv2.connectedComponents(sure_fg)\n",
    "        markers = markers + 1\n",
    "        markers[unknown == 255] = 0\n",
    "\n",
    "        # Apply the Watershed algorithm for segmentation\n",
    "        cv2.watershed(image_color, markers)\n",
    "        image_color[markers == -1] = [255, 0, 0]\n",
    "\n",
    "        # Prepare the final mask\n",
    "        final_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "        final_mask[markers > 1] = 255\n",
    "\n",
    "        # Display the result in a subplot\n",
    "        ax = axs[idx // 3, idx % 3]\n",
    "        ax.imshow(cv2.cvtColor(final_mask, cv2.COLOR_GRAY2RGB))\n",
    "        ax.set_title(f'Area Threshold: {area_threshold}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Adjust the layout and show the figure\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEDIR = '../data/predictions/Not identified/image_15.png'\n",
    "area_thresholds = [2000, 3000, 4000, 7000, 8000, 9000]\n",
    "process_and_plot_image(IMAGEDIR, area_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b3ae8",
   "metadata": {},
   "source": [
    "## 4.3 Evaluation of the segmentation + Postprocessing blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de622a2e",
   "metadata": {},
   "source": [
    "### Definition of new Utility Funcions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Computes the accuracy and Dice score of the model using a given loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader (DataLoader): The DataLoader for the dataset to evaluate.\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        device (str, optional): The device to use for computation. Defaults to \"cuda\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the accuracy and Dice score, both multiplied by 100.\n",
    "    \"\"\"\n",
    "    # Initialize counters for true positives, false positives, true negatives, and false negatives\n",
    "    num_tp = 0\n",
    "    num_fp = 0\n",
    "    num_tn = 0\n",
    "    num_fn = 0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)  # Move input data to the specified device\n",
    "            y = y.to(device).unsqueeze(1)  # Move targets to the device and adjust dimensions\n",
    "            y = torch.sigmoid(y)  # Apply sigmoid activation to targets\n",
    "            y = (y > 0.5).float()  # Binarize targets\n",
    "\n",
    "            preds = torch.sigmoid(model(x))  # Get model predictions and apply sigmoid activation\n",
    "            preds = (preds > 0.5).float()  # Binarize predictions\n",
    "\n",
    "            # Update counters\n",
    "            num_tp += (preds * y).sum()  # True positives\n",
    "            num_tn += ((1 - preds) * (1 - y)).sum()  # True negatives\n",
    "            num_fp += (preds * (1 - y)).sum()  # False positives\n",
    "            num_fn += ((1 - preds) * y).sum()  # False negatives\n",
    "\n",
    "    # Print the counts of false positives, false negatives, true positives, and true negatives\n",
    "    print(f\"FP: {num_fp}, FN: {num_fn}, TP: {num_tp}, TN: {num_tn}\")\n",
    "    \n",
    "    # Calculate accuracy and Dice score\n",
    "    accuracy = (num_tp + num_tn) / (num_tp + num_tn + num_fp + num_fn)\n",
    "    dice_score = (2 * num_tp) / ((2 * num_tp) + num_fp + num_fn + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return accuracy * 100, dice_score * 100  # Return accuracy and Dice score as percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fcbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(tensor_prediction, area_threshold):\n",
    "    \"\"\"\n",
    "    Postprocesses the tensor prediction to refine segmentation masks.\n",
    "\n",
    "    Parameters:\n",
    "        tensor_prediction (torch.Tensor): The tensor containing the prediction.\n",
    "        area_threshold (float): The minimum area for contours to be kept.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The final postprocessed mask tensor.\n",
    "    \"\"\"\n",
    "    # Convert tensor to numpy array and remove any singleton dimensions\n",
    "    image = tensor_prediction.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Ensure the image is in 8-bit format\n",
    "    if image.dtype != np.uint8:\n",
    "        # Scale the image to the range [0, 255] and convert to uint8\n",
    "        image = np.clip(image * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Handle color conversion if necessary\n",
    "    if len(image.shape) == 2:  # Check if the image is grayscale\n",
    "        # Convert grayscale image to BGR color format\n",
    "        image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        # Image is already in BGR format\n",
    "        image_color = image\n",
    "\n",
    "    # Define the kernel for morphological operations\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    # Apply morphological opening to remove small noise\n",
    "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    # Apply morphological closing to close small holes inside the foreground\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Convert the image to a binary image using Otsu's thresholding\n",
    "    _, binary = cv2.threshold(closing, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Create a mask of the same size as the image, initialized to zeros\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # Filter and draw contours based on area\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > area_threshold:\n",
    "            # Draw the contour on the mask if it meets the area threshold\n",
    "            cv2.drawContours(mask, [contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Further morphological cleaning by dilating the mask\n",
    "    sure_bg = cv2.dilate(mask, kernel, iterations=3)\n",
    "\n",
    "    # Apply distance transformation for segmentation\n",
    "    dist_transform = cv2.distanceTransform(sure_bg, cv2.DIST_L2, 5)\n",
    "    # Threshold the distance transform to get the foreground\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "    # Find the unknown region by subtracting the foreground from the background\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Label the connected components in the foreground\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1  # Increment all labels by 1 to distinguish from the background\n",
    "    markers[unknown == 255] = 0  # Mark the unknown region with zero\n",
    "\n",
    "    # Apply the watershed algorithm to segment the connected parts\n",
    "    cv2.watershed(image_color, markers)\n",
    "    # Mark the boundaries in red in the original image\n",
    "    image_color[markers == -1] = [255, 0, 0]\n",
    "\n",
    "    # Prepare the final mask in the same format as input\n",
    "    final_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    final_mask[markers > 1] = 1  # Mark the segmented regions\n",
    "\n",
    "    # Apply the necessary changes to the image\n",
    "    image[image > 0] = 1\n",
    "    \n",
    "    # Convert the final mask back to tensor format and add a batch dimension if necessary\n",
    "    final_tensor = torch.from_numpy(final_mask).unsqueeze(0)\n",
    "\n",
    "    return final_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "83a0b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_postprocessing(loader, model, device=\"cuda\", area_threshold=AREA_TRESHOLD):\n",
    "    \"\"\"\n",
    "    Computes the accuracy and Dice score of the model using a given loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader (DataLoader): The DataLoader for the dataset to evaluate.\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        device (str, optional): The device to use for computation. Defaults to \"cuda\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the accuracy and Dice score, both multiplied by 100.\n",
    "    \"\"\"\n",
    "    num_tp = 0  # Initialize true positives counter\n",
    "    num_fp = 0  # Initialize false positives counter\n",
    "    num_tn = 0  # Initialize true negatives counter\n",
    "    num_fn = 0  # Initialize false negatives counter\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for x, y in loader:  # Iterate over batches from the loader\n",
    "            x = x.to(device)  # Move input batch to the specified device\n",
    "            y = y.to(device).unsqueeze(1)  # Move target batch to the device and add channel dimension\n",
    "            y = torch.sigmoid(y)  # Apply sigmoid activation to targets\n",
    "            y = (y > 0.5).float()  # Binarize targets\n",
    "            preds = torch.sigmoid(model(x))  # Get model predictions and apply sigmoid activation\n",
    "            \n",
    "            # The changes go here\n",
    "            preds = preds.to('cpu')  # Move predictions to CPU\n",
    "            preds = (preds > 0.5).float()  # Binarize predictions\n",
    "            processed_tensors = []  # Initialize list to store processed tensors\n",
    "            \n",
    "            # Iterate over each tensor in the batch\n",
    "            for i in range(preds.size(0)):\n",
    "                single_tensor = preds[i]  # Extract individual tensor from batch\n",
    "\n",
    "                # Call postprocess function on the tensor\n",
    "                processed_tensor = postprocess(single_tensor, area_threshold)\n",
    "            \n",
    "                # Store the processed tensor\n",
    "                processed_tensors.append(processed_tensor)\n",
    "\n",
    "            # Concatenate all processed tensors back into a single tensor\n",
    "            final_tensor = torch.cat(processed_tensors, dim=0)\n",
    "            \n",
    "            preds = preds.to(device)  # Move predictions back to the original device\n",
    "            \n",
    "            # Move the final processed tensor to the original device\n",
    "            final_tensor = final_tensor.to(device)\n",
    "            final_tensor = final_tensor.unsqueeze(1)  # Add channel dimension\n",
    "            final_tensor = (final_tensor > 0.5).float()  # Binarize final tensor\n",
    "            \n",
    "            # Convert tensors to binary\n",
    "            preds_binary = (preds > 0.5).float()\n",
    "            final_tensor_binary = (final_tensor > 0.5).float()\n",
    "            \n",
    "            # Ensure both tensors are on the correct device\n",
    "            preds_binary = preds_binary.to(device)\n",
    "            final_tensor_binary = final_tensor_binary.to(device)\n",
    "\n",
    "            # Initialize counters\n",
    "            num_tp = torch.tensor(0.0, device=device)\n",
    "            num_tn = torch.tensor(0.0, device=device)\n",
    "            num_fp = torch.tensor(0.0, device=device)\n",
    "            num_fn = torch.tensor(0.0, device=device)\n",
    "\n",
    "            # Calculate TP, TN, FP, FN\n",
    "            #num_tp += (final_tensor_binary * preds_binary).sum()\n",
    "            #num_tn += ((1 - final_tensor_binary) * (1 - preds_binary)).sum()\n",
    "            #num_fp += (final_tensor_binary * (1 - preds_binary)).sum()\n",
    "            #num_fn += ((1 - final_tensor_binary) * preds_binary).sum()\n",
    "\n",
    "            # Optional: print results\n",
    "            #print(f\"True Positives: {num_tp.item()}\")\n",
    "            #print(f\"True Negatives: {num_tn.item()}\")\n",
    "            #print(f\"False Positives: {num_fp.item()}\")\n",
    "            #print(f\"False Negatives: {num_fn.item()}\")\n",
    "\n",
    "            # Calculate TP, TN, FP, FN based on final tensor and targets\n",
    "            num_tp += (final_tensor_binary * y).sum()\n",
    "            num_tn += ((1 - final_tensor_binary) * (1 - y)).sum()\n",
    "            num_fp += (final_tensor_binary * (1 - y)).sum()\n",
    "            num_fn += ((1 - final_tensor_binary) * y).sum()\n",
    "            \n",
    "    # Calculate accuracy and Dice score\n",
    "    accuracy = (num_tp + num_tn) / (num_tp + num_tn + num_fp + num_fn)\n",
    "    dice_score = (2 * num_tp) / ((2 * num_tp) + num_fp + num_fn + 1e-8)\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return accuracy * 100, dice_score * 100  # Return accuracy and Dice score in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad4665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_plot(dice_scores, dice_scores_postprocess, graph_savefile, corr_name=None):\n",
    "    \"\"\"\n",
    "    Plots a spider plot comparing original and postprocessed Dice scores.\n",
    "\n",
    "    Parameters:\n",
    "        dice_scores (numpy.ndarray): Array of original Dice scores.\n",
    "        dice_scores_postprocess (numpy.ndarray): Array of postprocessed Dice scores.\n",
    "        graph_savefile (str): Path to save the generated plot.\n",
    "        corr_name (str, optional): Name of the corruption type for the plot title. Defaults to None.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(graph_savefile), exist_ok=True)  # Create directories if they don't exist\n",
    "    \n",
    "    labels = np.array(SEVERITIES)  # Convert severity levels to a NumPy array\n",
    "    num_vars = len(labels)  # Number of variables (severity levels)\n",
    "    \n",
    "    # Compute angles for each bar in the plot\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    \n",
    "    # Close the loop for plotting by appending the first value to the end\n",
    "    dice_scores = np.concatenate((dice_scores, [dice_scores[0]]))  # Append the first dice score to the end\n",
    "    dice_scores_postprocess = np.concatenate((dice_scores_postprocess, [dice_scores_postprocess[0]]))  # Append the first postprocessed dice score to the end\n",
    "    angles += angles[:1]  # Append the first angle to the end\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))  # Create a polar subplot\n",
    "    \n",
    "    # Plot the original Dice scores\n",
    "    ax.fill(angles, dice_scores, color='blue', alpha=0.6)\n",
    "    ax.plot(angles, dice_scores, color='blue', linewidth=2, label='Original')\n",
    "    \n",
    "    # Plot the postprocessed Dice scores\n",
    "    ax.fill(angles, dice_scores_postprocess, color='red', alpha=0.4)\n",
    "    ax.plot(angles, dice_scores_postprocess, color='red', linewidth=2, label='Postprocessed')\n",
    "    \n",
    "    # Set labels for each slice\n",
    "    ax.set_xticks(angles[:-1])  # Set the ticks at each angle (except the last one to avoid duplication)\n",
    "    ax.set_xticklabels(labels, fontsize=14, fontweight='bold', color='navy')  # Set the labels for each tick\n",
    "    \n",
    "    # Set the range for each slice\n",
    "    ax.set_ylim(0, 100)  # Set the y-axis range from 0 to 100\n",
    "    \n",
    "    # Aesthetic improvements\n",
    "    ax.set_facecolor('floralwhite')  # Set background color\n",
    "    ax.grid(color='grey', linestyle='--', linewidth=0.5)  # Customize the grid\n",
    "    \n",
    "    # Set the plot title\n",
    "    title = f'{corr_name} Dice Score Spider Plot' if corr_name else 'Dice Score Spider Plot'\n",
    "    plt.title(title, fontsize=16, fontweight='bold')  # Set the plot title\n",
    "    \n",
    "    plt.legend(loc='upper right', fontsize=12)  # Add legend to the plot\n",
    "    plt.savefig(graph_savefile)  # Save the plot to the specified file\n",
    "    plt.close()  # Close the plot to free memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e8a8d",
   "metadata": {},
   "source": [
    "### Definition of the Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ede1807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (ups): ModuleList(\n",
       "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downs): ModuleList(\n",
       "    (0): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AREA_THRESHOLD = 500  # Adjusted because we are applying postprocess on smaller images\n",
    "IMAGE_HEIGHT = 270  # Height of the images\n",
    "IMAGE_WIDTH = 480  # Width of the images\n",
    "FOLDER = '../dataset/test-C'  # Path to the main dataset folder\n",
    "SEVERITIES = ['s1', 's2', 's3', 's4', 's5']  # List of severity levels for corruptions\n",
    "SUBFOLDERS = ['imgs', 'masks']  # Subfolders for images and masks\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'  # Path to save graph results\n",
    "CHECKPOINT_PATH = './models/unet_checkpoint.pth.tar'  # Path to the model checkpoint file\n",
    "\n",
    "# Define transformations for corrupted images\n",
    "corr_transforms = A.Compose([\n",
    "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True),  # Resize images to specified dimensions\n",
    "    A.Normalize(  # Normalize images to zero mean and unit variance\n",
    "        mean=[0.0, 0.0, 0.0],\n",
    "        std=[1.0, 1.0, 1.0],\n",
    "        max_pixel_value=255.0,\n",
    "    ),\n",
    "    ToTensorV2(),  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "def get_corruption_dataset_loaders(img_dir, mask_dir, batch_size, transform, num_workers=4, pin_memory=True):\n",
    "    \"\"\"Create DataLoader for corrupted dataset.\"\"\"\n",
    "    # Initialize dataset with specified directories and transformations\n",
    "    corr_ds = RobotDataset(image_dir=img_dir, mask_dir=mask_dir, transform=transform)\n",
    "    # Create DataLoader for the dataset with given parameters\n",
    "    corr_loader = DataLoader(corr_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory, worker_init_fn=worker_init_fn)\n",
    "    return corr_loader\n",
    "\n",
    "# Initialize model and load checkpoint\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)  # Create UNET model and move it to the specified device\n",
    "load_checkpoint(torch.load(CHECKPOINT_PATH), model)  # Load the model checkpoint\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3868fd",
   "metadata": {},
   "source": [
    "### 4.3.1 c=0 Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "203a8026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3736.0, FN: 29.0, TP: 37260.0, TN: 7086975.0\n",
      "FP: 3841.0, FN: 23.0, TP: 36593.0, TN: 6957943.0\n",
      "FP: 12129.0, FN: 31.0, TP: 37258.0, TN: 7078582.0\n",
      "FP: 53162.0, FN: 45.0, TP: 37244.0, TN: 7037549.0\n",
      "FP: 142446.0, FN: 117.0, TP: 37172.0, TN: 6948265.0\n",
      "[95.19065094 94.9850769  85.97074127 58.33274841 34.27459717]\n",
      "[96.46716309 92.09622192 95.93479156 95.78102112 95.24790955]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'  # Path to the main folder containing the datasets\n",
    "CORRUPTION = 'c0'  # Type of corruption applied to the dataset\n",
    "SEVERITIES = ['s1', 's2', 's3', 's4', 's5']  # Different levels of severity of the corruption\n",
    "SUBFOLDERS = ['imgs', 'masks']  # Subfolders for images and masks within each severity level\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'  # Path to save the generated graph\n",
    "AREA_THRESHOLD = 8000\n",
    "name = 'Gaussian noise'  # Name of the corruption type\n",
    "\n",
    "# Array to hold Dice scores for each severity level\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    # Construct paths to the image and mask directories for the current severity level\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    # Load the corrupted datasets\n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    # Evaluate accuracy and Dice score before postprocessing\n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    # Evaluate accuracy and Dice score after postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the Dice scores\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "\n",
    "# Print the Dice scores for all severity levels\n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generate the spider plot to visualize the Dice scores\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395676c",
   "metadata": {},
   "source": [
    "### 4.3.2 c=1 Shot Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4073485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3932.0, FN: 27.0, TP: 37262.0, TN: 7086779.0\n",
      "FP: 5586.0, FN: 26.0, TP: 37263.0, TN: 7085125.0\n",
      "FP: 24287.0, FN: 29.0, TP: 37260.0, TN: 7066424.0\n",
      "FP: 113242.0, FN: 47.0, TP: 37242.0, TN: 6977469.0\n",
      "FP: 230437.0, FN: 86.0, TP: 37203.0, TN: 6860274.0\n",
      "[94.95559692 92.99707794 75.39762878 39.66704559 24.40108871]\n",
      "[96.19619751 96.43956757 96.07313538 94.90003967 95.3412323 ]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c1'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Shot Noise'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f99c7",
   "metadata": {},
   "source": [
    "### 4.3.3 c=2 Impulse Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "758ee69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3726.0, FN: 24.0, TP: 37265.0, TN: 7086985.0\n",
      "FP: 4145.0, FN: 32.0, TP: 37257.0, TN: 7086566.0\n",
      "FP: 6649.0, FN: 27.0, TP: 37262.0, TN: 7084062.0\n",
      "FP: 28995.0, FN: 40.0, TP: 37249.0, TN: 7061716.0\n",
      "FP: 85042.0, FN: 115.0, TP: 37174.0, TN: 7005669.0\n",
      "[95.20950317 94.69189453 91.77832794 71.95580292 46.61170578]\n",
      "[96.72683716 92.44219971 91.5531311  95.24590302 95.31038666]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c2'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Impulse Noise'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710f7d7",
   "metadata": {},
   "source": [
    "### 4.3.4 c=4 Glass Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e80092dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 2347.0, FN: 307.0, TP: 36982.0, TN: 7088364.0\n",
      "FP: 1307.0, FN: 1016.0, TP: 36273.0, TN: 7089404.0\n",
      "FP: 727.0, FN: 2160.0, TP: 35129.0, TN: 7089984.0\n",
      "FP: 314.0, FN: 3982.0, TP: 33307.0, TN: 7090397.0\n",
      "FP: 4.0, FN: 36616.0, TP: 673.0, TN: 7090707.0\n",
      "[96.53606415 96.89724731 96.05304718 93.94161987  3.54527712]\n",
      "[97.2215271  95.42256927 95.28530121 92.15415955  0.        ]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c4'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Glass Blur'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7987e37",
   "metadata": {},
   "source": [
    "### 4.3.5 c=5 Motion Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e83483c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 6418.0, FN: 74.0, TP: 37215.0, TN: 7084293.0\n",
      "FP: 10044.0, FN: 54.0, TP: 37235.0, TN: 7080667.0\n",
      "FP: 10044.0, FN: 54.0, TP: 37235.0, TN: 7080667.0\n",
      "FP: 10044.0, FN: 54.0, TP: 37235.0, TN: 7080667.0\n",
      "FP: 13792.0, FN: 84.0, TP: 37205.0, TN: 7076919.0\n",
      "[91.97746277 88.05931091 88.05931091 88.05931091 84.28289795]\n",
      "[93.99585724 90.27441406 91.07578278 90.84861755 87.42728424]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c5'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Motion Blur'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc88d52",
   "metadata": {},
   "source": [
    "### 4.3.6 c=6 Fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4e7568c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 991.0, FN: 1434.0, TP: 35855.0, TN: 7089720.0\n",
      "FP: 723.0, FN: 2757.0, TP: 34532.0, TN: 7089988.0\n",
      "FP: 671.0, FN: 4369.0, TP: 32920.0, TN: 7090040.0\n",
      "FP: 710.0, FN: 3937.0, TP: 33352.0, TN: 7090001.0\n",
      "FP: 1172.0, FN: 5504.0, TP: 31785.0, TN: 7089539.0\n",
      "[96.72893524 95.20291138 92.88938904 93.48712921 90.49625397]\n",
      "[96.13828278 93.83876801 93.09766388 77.81071472 53.93540192]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c6'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Fog'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637bb13",
   "metadata": {},
   "source": [
    "### 4.3.7 c=7 Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cb44b4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3698.0, FN: 32.0, TP: 37257.0, TN: 7087013.0\n",
      "FP: 3823.0, FN: 55.0, TP: 37234.0, TN: 7086888.0\n",
      "FP: 3815.0, FN: 77.0, TP: 37212.0, TN: 7086896.0\n",
      "FP: 3744.0, FN: 108.0, TP: 37181.0, TN: 7086967.0\n",
      "FP: 3674.0, FN: 189.0, TP: 37100.0, TN: 7087037.0\n",
      "[95.23286438 95.05016327 95.03038788 95.07505035 95.05142975]\n",
      "[96.24013519 92.38829803 95.95375824 92.39871216 91.96096039]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c7'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Brightness'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52655be",
   "metadata": {},
   "source": [
    "### 4.3.8 c=8 Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f3721531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 182.0, FN: 3030.0, TP: 34259.0, TN: 7090529.0\n",
      "FP: 0.0, FN: 13010.0, TP: 24279.0, TN: 7090711.0\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "[95.52209473 78.86889648  0.          0.          0.        ]\n",
      "[94.10299683  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c8'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Contrast'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52e82e",
   "metadata": {},
   "source": [
    "### 4.3.9 c=9 Elastic Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b4029bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 14130.0, FN: 10046.0, TP: 27243.0, TN: 7076581.0\n",
      "FP: 22334.0, FN: 18106.0, TP: 19183.0, TN: 7068377.0\n",
      "FP: 4986.0, FN: 891.0, TP: 36398.0, TN: 7085725.0\n",
      "FP: 4970.0, FN: 1073.0, TP: 36216.0, TN: 7085741.0\n",
      "FP: 5335.0, FN: 1242.0, TP: 36047.0, TN: 7085376.0\n",
      "[69.26597595 48.68411255 92.52983856 92.29946136 91.63986206]\n",
      "[64.01673889 34.24013138 91.26007843 94.87046051 91.56062317]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c9'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Elastic Transform'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0adf5",
   "metadata": {},
   "source": [
    "### 4.3.10 c=11 Speckle noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "21cc33c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3918.0, FN: 22.0, TP: 37267.0, TN: 7086793.0\n",
      "FP: 4104.0, FN: 23.0, TP: 37266.0, TN: 7086607.0\n",
      "FP: 20352.0, FN: 22.0, TP: 37267.0, TN: 7070359.0\n",
      "FP: 50357.0, FN: 25.0, TP: 37264.0, TN: 7040354.0\n",
      "FP: 119343.0, FN: 30.0, TP: 37259.0, TN: 6971368.0\n",
      "[94.97922516 94.75330353 78.53289032 59.6653595  38.43293381]\n",
      "[96.38528442 96.46395874 95.72859192 92.40705109 91.6518631 ]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c11'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Speckle Noise'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385939d",
   "metadata": {},
   "source": [
    "### 4.3.11 c=12 Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9279411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 762.0, FN: 1723.0, TP: 35566.0, TN: 7089949.0\n",
      "FP: 189.0, FN: 36842.0, TP: 447.0, TN: 7090522.0\n",
      "FP: 102.0, FN: 37191.0, TP: 98.0, TN: 7090609.0\n",
      "FP: 24.0, FN: 37281.0, TP: 8.0, TN: 7090687.0\n",
      "FP: 0.0, FN: 37289.0, TP: 0.0, TN: 7090711.0\n",
      "[9.66244202e+01 2.35728407e+00 5.22820055e-01 4.28713039e-02\n",
      " 0.00000000e+00]\n",
      "[96.36540985  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c12'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Gaussian Blur'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafafa4",
   "metadata": {},
   "source": [
    "### 4.3.12 c=13 Spatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "665dd0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 3651.0, FN: 27.0, TP: 37262.0, TN: 7087060.0\n",
      "FP: 3284.0, FN: 59.0, TP: 37230.0, TN: 7087427.0\n",
      "FP: 3144.0, FN: 76.0, TP: 37213.0, TN: 7087567.0\n",
      "FP: 221592.0, FN: 18.0, TP: 37271.0, TN: 6869119.0\n",
      "FP: 901334.0, FN: 12.0, TP: 37277.0, TN: 6189377.0\n",
      "[95.29679108 95.70324707 95.85297394 25.17018318  7.63951254]\n",
      "[96.18859863 96.25656891 96.32398224 94.49280548 92.29705811]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c13'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Spatter'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41209f",
   "metadata": {},
   "source": [
    "### 4.3.13 c=14 Saturate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4bece230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 843.0, FN: 1365.0, TP: 35924.0, TN: 7089868.0\n",
      "FP: 281.0, FN: 36277.0, TP: 1012.0, TN: 7090430.0\n",
      "FP: 5105.0, FN: 5.0, TP: 37284.0, TN: 7085606.0\n",
      "FP: 464227.0, FN: 1.0, TP: 37288.0, TN: 6626484.0\n",
      "FP: 4944052.0, FN: 1.0, TP: 37288.0, TN: 2146659.0\n",
      "[97.01847076  5.2459693  93.58669281 13.84102535  1.48598361]\n",
      "[96.84901428  0.         95.96188354 23.48732567  0.75491244]\n"
     ]
    }
   ],
   "source": [
    "FOLDER = '../dataset/test-C'\n",
    "CORRUPTION = 'c14'\n",
    "SEVERITIES= ['s1','s2','s3','s4','s5']\n",
    "SUBFOLDERS = ['imgs','masks']\n",
    "GRAPH_SAVEFILE = f'../results/saved_graphs/{CORRUPTION}'\n",
    "name = 'Saturate'\n",
    "# Array to hold dice scores\n",
    "dice_scores = np.zeros(len(SEVERITIES))\n",
    "dice_scores_postprocess = np.zeros(len(SEVERITIES))\n",
    "# Main loop to process each severity level\n",
    "for i, severity in enumerate(SEVERITIES):\n",
    "    img_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[0]}'\n",
    "    mask_dir = f'{FOLDER}/{CORRUPTION}/{severity}/{SUBFOLDERS[1]}'\n",
    "    \n",
    "    test_loader = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    test_loader_corr = get_corruption_dataset_loaders(img_dir, mask_dir, BATCH_SIZE, corr_transforms, NUM_WORKERS, PIN_MEMORY)\n",
    "    \n",
    "    accuracy, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n",
    "    \n",
    "    #After postprocessing\n",
    "    accuracy2, dice_score2 = check_accuracy_postprocessing(test_loader_corr, model, device=DEVICE, area_threshold=AREA_TRESHOLD)\n",
    "    \n",
    "    # Store the dice score\n",
    "    dice_scores[i] = dice_score\n",
    "    dice_scores_postprocess[i] = dice_score2\n",
    "    \n",
    "print(dice_scores)\n",
    "print(dice_scores_postprocess)\n",
    "\n",
    "# Generating the spider plot after processing all severities\n",
    "spider_plot(dice_scores, dice_scores_postprocess, graph_savefile=GRAPH_SAVEFILE, corr_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b7e58",
   "metadata": {},
   "source": [
    "## 3.5 Filtering Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6629da",
   "metadata": {},
   "source": [
    "### Define Camera Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9245970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera:\n",
    "\n",
    "\tdef __init__(self,MTXDIR='../data/calibration_matrixes/mtx.npy', DISTDIR = './data/calibration_matrixes/distortion.npy'):\n",
    "\n",
    "\t\t# Camera configuration properties\n",
    "\t\tself.color_resolution = (1920, 1080)\n",
    "\t\tself.depth_resolution = (1280, 720)\n",
    "\t\tself.frames_per_second = 30\n",
    "\t\tself.id = '821312060307'\n",
    "\n",
    "\t\t# Camera connection properties\n",
    "\t\tself.conn = None\n",
    "\t\tself.conf = None\n",
    "\t\tself.align = None\n",
    "\n",
    "\t\t# Camera calibration properties (calculated from 'abb_camera_calibration.py'-file)\n",
    "\t\tself.mtx = np.load(MTXDIR)\n",
    "\t\tself.dist = np.load(DISTDIR)\n",
    "\n",
    "\t\t# Chessboard properties\n",
    "\t\tself.h = 14\n",
    "\t\tself.b = 9\n",
    "\t\tself.size = 17.4 # mm\n",
    "\n",
    "\t# Start camera readout\n",
    "\tdef start(self):\n",
    "\n",
    "\t\t# Connect\n",
    "\t\tself.conn = realsense.pipeline()\n",
    "\n",
    "\t\t# Config\n",
    "\t\tself.conf = realsense.config()\n",
    "\t\tself.conf.enable_device(self.id)\n",
    "\t\tself.conf.enable_stream(realsense.stream.depth, self.depth_resolution[0], self.depth_resolution[1], realsense.format.z16, self.frames_per_second)\n",
    "\t\tself.conf.enable_stream(realsense.stream.color, self.color_resolution[0], self.color_resolution[1], realsense.format.bgr8, self.frames_per_second)\n",
    "\t\t\n",
    "\t\t# Start streaming\n",
    "\t\tself.conn.start(self.conf)\n",
    "\n",
    "\t\t# Align images\n",
    "\t\tself.align = realsense.align(realsense.stream.color)\n",
    "\n",
    "\t# Stop camera readout\n",
    "\tdef close(self):\n",
    "\n",
    "\t\t# Stop streaming\n",
    "\t\tself.conn.stop()\n",
    "\n",
    "\t# Read frame\n",
    "\tdef read(self):\n",
    "\n",
    "\t\t# Wait for image\n",
    "\t\tframes = self.conn.wait_for_frames()\n",
    "\n",
    "\t\t# Align images\n",
    "\t\taligned_frames = self.align.process(frames)\n",
    "\n",
    "\t\t# Retreive images\n",
    "\t\tcolor_frame = aligned_frames.get_color_frame()\n",
    "\t\tdepth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "\t\t# Convert to arrays\n",
    "\t\tdepth = np.asanyarray(depth_frame.get_data())\n",
    "\t\tcolor = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "\t\treturn color, depth\n",
    "\n",
    "\t# Get depth of pixel\n",
    "\tdef get_pixel_depth(self, image, pixel):\n",
    "\t\tdepth = image[pixel[1], pixel[0]]\n",
    "\t\treturn depth\n",
    "\n",
    "\t# Extrinsic calibration\n",
    "\tdef extrinsic_calibration(self, img):\n",
    "\n",
    "\t\t# termination criteria\n",
    "\t\tcriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\t\t# objectpunten van het schaakbord voorbereiden\n",
    "\t\tobjp = np.zeros((self.b * self.h, 3), numpy.float32)\n",
    "\t\tobjp[:, :2] = np.mgrid[0:self.b, 0:self.h].T.reshape(-1, 2)\n",
    "\t\tobjp = self.size * objp\n",
    "\n",
    "\t\t# Convert to grayscale\n",
    "\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t\t# Get chessboard corners\n",
    "\t\tret, corners = cv2.findChessboardCornersSB(gray, (self.b, self.h), cv2.CALIB_CB_MARKER)\n",
    "\t\n",
    "\t\t# If corners are found\n",
    "\t\tif ret == True:\n",
    "\t\t\t\n",
    "\t\t\t# Refine corners\n",
    "\t\t\tcorners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "\t\t\t# Extrinsic calibration\n",
    "\t\t\tret, rvecs, tvecs, _ = cv2.solvePnPRansac(objp, corners2, self.mtx, self.dist)\n",
    "\n",
    "\t\t\t# Get extrinsic matrix\n",
    "\t\t\trvecs_matrix = cv2.Rodrigues(rvecs)[0]\n",
    "\t\t\textrinsics = np.hstack((rvecs_matrix, tvecs))\n",
    "\t\t\textrinsics = np.vstack((extrinsics, [0.0, 0.0, 0.0, 1.0]))\n",
    "\n",
    "\t\t\treturn ret, corners2, rvecs, tvecs, extrinsics\n",
    "\n",
    "\t\t# If corners not found\n",
    "\t\telse:\n",
    "\t\t\treturn None, None, None, None, None\n",
    "\n",
    "\n",
    "\t# Covert 2D to 3D cooridnates\n",
    "\tdef intrinsic_trans(self, pixel, z, mtx):\n",
    "\t\tif (z):\n",
    "\t\t\tx = (pixel[0] - mtx[0, 2]) / mtx[0, 0] * z\n",
    "\t\t\ty = (pixel[1] - mtx[1, 2]) / mtx[1, 1] * z\n",
    "\t\t\treturn x, y, z\n",
    "\t\telse:\n",
    "\t\t\treturn None, None, None\n",
    "\t\t\n",
    "\t# Covert 3D to 2D cooridnates\n",
    "\tdef intrinsic_trans_inv(self, x, y, z, mtx):\n",
    "\t\tif (z):\n",
    "\t\t\tu = x * mtx[0, 0] * z + mtx[0, 2] \n",
    "\t\t\tv = y * mtx[1, 1] * z + mtx[1, 2]\n",
    "\t\t\treturn u, v\n",
    "\t\telse:\n",
    "\t\t\treturn None, None\n",
    "\n",
    "#generate camera object\n",
    "cam = Camera(os.path.join(TRANFMATRIX,'mtx.npy'),os.path.join(TRANFMATRIX,'distortion.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530913b2",
   "metadata": {},
   "source": [
    "### 3.5.1 Data Paths and Parameter loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute camera matrix and distortion mappings if possible\n",
    "# This assumes all images have the same dimension, which should be validated beforehand\n",
    "TESTDIR_IMGS = '../data/images_rgb/'  # Directory containing the test images\n",
    "SAVEDIR = '../data/calibration_matrixes/'  # Directory to save the calibration matrices\n",
    "AREA_THRESHOLD = 8000  # Threshold area for processing\n",
    "\n",
    "# Get the path of a sample image from the test directory\n",
    "sample_image_path = os.path.join(TESTDIR_IMGS, os.listdir(TESTDIR_IMGS)[0])\n",
    "# Read the sample image using OpenCV\n",
    "sample_image = cv2.imread(sample_image_path)\n",
    "# Get the height and width of the sample image\n",
    "h, w = sample_image.shape[:2]\n",
    "\n",
    "# Compute the optimal new camera matrix and region of interest\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(cam.mtx, cam.dist, (w, h), 1, (w, h))\n",
    "# Initialize the undistort rectify map\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(cam.mtx, cam.dist, None, newcameramtx, (w, h), 5)\n",
    "\n",
    "# Define the resizing transformation to be applied post prediction\n",
    "post_predict_resize = A.Resize(height=1080, width=1920, interpolation=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b7af5",
   "metadata": {},
   "source": [
    "First, given the healthy dataset, I calculate the normal eccentricity and radius features of the pieces and compute the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30464cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalfeat = []  # List to store features of each image\n",
    "\n",
    "for image_file in os.listdir(TESTDIR_IMGS):\n",
    "    image_path = os.path.join(TESTDIR_IMGS, image_file)  # Get the full path of the image file\n",
    "    image = cv2.imread(image_path)  # Read the image using OpenCV\n",
    "    image = cv2.warpPerspective(image, M, (w, h))  # Apply perspective transformation\n",
    "\n",
    "    # Convert image to PIL, apply transforms, and predict with the model\n",
    "    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR image to RGB and then to PIL format\n",
    "    transformed = test_transforms(image=np.array(image))  # Apply transformations to the image\n",
    "    image = transformed[\"image\"].unsqueeze(0).to(DEVICE)  # Convert transformed image to tensor and move to device\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        prediction = model(image)  # Get model prediction\n",
    "    prediction = torch.sigmoid(prediction)  # Apply sigmoid activation to prediction\n",
    "    prediction = (prediction > 0.5).float()  # Binarize prediction\n",
    "\n",
    "    # Resize prediction and save\n",
    "    prediction = prediction.squeeze().cpu().numpy()  # Remove batch dimension and move to CPU\n",
    "    resized_prediction = post_predict_resize(image=prediction)['image']  # Resize prediction using defined transformation\n",
    "    tensor_prediction = torch.from_numpy(resized_prediction).unsqueeze(0)  # Convert resized prediction back to tensor\n",
    "    \n",
    "    pieces_features = get_pieces_features(tensor_prediction)  # Extract features from the prediction\n",
    "    normalfeat.append(pieces_features)  # Append extracted features to the list\n",
    "    \n",
    "result = stats(normalfeat, SAVEDIR)  # Compute and save statistics of features\n",
    "print(result)  # Print the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef69b0b4",
   "metadata": {},
   "source": [
    "## 3.6 Segmentation2RobotFrame (x,y,z)_RF Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9d1ce",
   "metadata": {},
   "source": [
    "In this part the final block of the model will be developed, from the post-processed segmented image to obtaining the position (x,y,z) in the robot dataframe. This will be done through two approaches: in the first approach, transformation matrices will be used, and in the second approach, an MLP will be trained to simulate the transformation matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9bcc1a",
   "metadata": {},
   "source": [
    "### Define Parameters, Data Paths and Transformation Matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8bf91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANFMATRIX = '../data/calibration_matrixes/'\n",
    "PRED_TESTDIR = '../data/predictions/'\n",
    "TESTDIR_IMGS = '../data/images_rgb_CF/'\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Set device to CUDA if available, otherwise use CPU.\n",
    "print(DEVICE)\n",
    "CHECKPOINT_PATH = \"./models/unet_checkpoint.pth.tar\"  # Path to the model checkpoint\n",
    "IMAGE_HEIGHT = 270  \n",
    "IMAGE_WIDTH  = 480\n",
    "\n",
    "#Load T_bc (Transformation matrix from robot base frame to camera frame)\n",
    "T_bc = np.load(os.path.join(TRANFMATRIX,'T_bc.npy'))\n",
    "#Load perspective matrix (calculated using the image_rectification_test.py file)\n",
    "M = np.load(os.path.join(TRANFMATRIX,'perspective_transform.npy'))\n",
    "\n",
    "# Define the transformations for validation images.\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),  # Resize images to defined dimensions.\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],  # Normalize images with a mean of 0.\n",
    "            std=[1.0, 1.0, 1.0],    # Standard deviation for normalization.\n",
    "            max_pixel_value=255.0,  # Maximum pixel value in input images.\n",
    "        ),\n",
    "        ToTensorV2(),  # Convert images to tensor format compatible with PyTorch.\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1f334",
   "metadata": {},
   "source": [
    "### 3.6.1 First Approach (Using Transformation Matrixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c0b56",
   "metadata": {},
   "source": [
    "#### Camera and Tool Correction C_x, C_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute camera matrix and distortion mappings if possible\n",
    "# This assumes all images have the same dimension, which should be validated beforehand\n",
    "SAVEDIR = '../data/calibration_matrixes/'\n",
    "STATSDIR= os.path.join(SAVEDIR, 'feature_stats.json')\n",
    "\n",
    "#TESTDIR_IMGS = '../data/images-rgb-C/c13/s4/imgs'\n",
    "TESTDIR_IMGS = '../data/images_rgb_CF' \n",
    "TESTDIR_DEPTH = '../data/imgs_depth/'\n",
    "TESTDIR_LABELSGT = '../data/labels_gt_RF/'\n",
    "\n",
    "BASE_DATASET = '../data/images-rgb-C'\n",
    "\n",
    "SIGMA = 1\n",
    "AREA_TRESHOLD = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dae1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store differences\n",
    "differences = []\n",
    "start_time = time.time()  # Record the start time of processing\n",
    "NON_DETECTED_PIECES = 0  # Initialize the counter for non-detected pieces\n",
    "\n",
    "print(f'Images Folder: {TESTDIR_IMGS} ')\n",
    "SIGMA = 3  # Set the sigma value for filtering\n",
    "\n",
    "# Iterate through all image files in the directory\n",
    "for image_file in os.listdir(TESTDIR_IMGS):\n",
    "    \n",
    "    # Read the image, depth, and ground truth labels\n",
    "    image = cv2.imread(os.path.join(TESTDIR_IMGS, image_file))\n",
    "    depth = np.load(os.path.join(TESTDIR_DEPTH, image_file.replace('.jpg', '.npy')))\n",
    "    labels_gt = read_labels(os.path.join(TESTDIR_LABELSGT, image_file.replace('.jpg', '.txt')))\n",
    "    \n",
    "    # Warp the image using a perspective transformation\n",
    "    image = cv2.warpPerspective(image, M, (w, h))\n",
    "    \n",
    "    # Convert the image to PIL format, apply transformations, and predict with the model\n",
    "    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    transformed = test_transforms(image=np.array(image))\n",
    "    image = transformed[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(image)  # Make a prediction using the model\n",
    "    prediction = torch.sigmoid(prediction)  # Apply sigmoid activation\n",
    "    prediction = (prediction > 0.5).float()  # Threshold the prediction\n",
    "\n",
    "    # Resize the prediction and save\n",
    "    prediction = prediction.squeeze().cpu().numpy()\n",
    "    resized_prediction = post_predict_resize(image=prediction)['image']\n",
    "    tensor_prediction = torch.from_numpy(resized_prediction).unsqueeze(0)\n",
    "   \n",
    "    # Postprocess the prediction\n",
    "    tensor_prediction = postprocess(tensor_prediction, AREA_TRESHOLD)    \n",
    "    \n",
    "    # Get features of detected pieces\n",
    "    pieces_features = get_pieces_features(tensor_prediction)\n",
    "    \n",
    "    # Filter objects that are not similar to images\n",
    "    pieces_features = filter_pieces(STATSDIR, pieces_features, SIGMA)\n",
    "    save_path = os.path.join(PRED_TESTDIR, f\"{image_file.split('.')[0]}.png\")\n",
    "    \n",
    "    if len(pieces_features) != 0:\n",
    "        for piece in pieces_features: \n",
    "            # Get piece data\n",
    "            center = piece['centroid']\n",
    "            radius = piece['radius']\n",
    "            \n",
    "            # Transform pixel on warped image back to original image\n",
    "            new_pixel = np.dot(np.linalg.inv(M), np.array([[center[0]], [center[1]], [1]]))\n",
    "            center = [int(new_pixel[0][0]/new_pixel[2][0]), int(new_pixel[1][0]/new_pixel[2][0])]\n",
    "            \n",
    "            # Get pixel depth \n",
    "            pixel_depth = depth[center[1], center[0]]\n",
    "            \n",
    "            # Transform 2D to 3D camera coordinates\n",
    "            xcam, ycam, zcam = cam.intrinsic_trans(center, pixel_depth, cam.mtx)\n",
    "\n",
    "            # Transform camera coordinates to robot base frame using T_bc\n",
    "            p_bt = np.dot(T_bc, np.array([[xcam], [ycam], [zcam], [1]]))  # Position of the object in robot base frame\n",
    "\n",
    "            # Create pick position for robot considering grip height and tool offset\n",
    "            xyz = np.array([p_bt[0][0], p_bt[1][0], p_bt[2][0]]) \n",
    "            xyz[2] = 5\n",
    "            \n",
    "            x_pred, y_pred = xyz[0], xyz[1]\n",
    "            x_gt, y_gt = labels_gt[0], labels_gt[1]\n",
    "            \n",
    "            # Save the differences\n",
    "            differences.append((x_gt - x_pred, y_gt - y_pred))\n",
    "            actual_error = np.array((x_gt - x_pred, y_gt - y_pred)) \n",
    "            r_value = math.sqrt(actual_error[0]**2 + actual_error[1]**2)\n",
    "            if r_value > 25.0:\n",
    "                print(image_file)\n",
    "                save_annotated_image(tensor_prediction, save_path, pieces_features)\n",
    "\n",
    "    else:\n",
    "        # Increment the counter for non-detected pieces\n",
    "        NON_DETECTED_PIECES += 1\n",
    "        print(image_file)\n",
    "\n",
    "# Convert differences to numpy array and compute r values\n",
    "errors_np = np.array(differences)     \n",
    "r_values = np.sqrt(np.sum(errors_np**2, axis=1))\n",
    "\n",
    "# Calculate the mean and standard deviation of r values\n",
    "mean_r = np.mean(r_values)\n",
    "std_r = np.std(r_values)\n",
    "\n",
    "# Create a tuple with the mean and standard deviation\n",
    "result = (mean_r, std_r)\n",
    "print(f\"Mean of errors: {mean_r}\")\n",
    "print(f\"Standard deviation of errors: {std_r}\")\n",
    "\n",
    "# Calculate the total number of pieces and detection percentage\n",
    "TOTAL_PIECES = len(os.listdir(TESTDIR_IMGS))\n",
    "print(f'Detected percentage: {(1-(NON_DETECTED_PIECES/TOTAL_PIECES)) * 100}')\n",
    "\n",
    "# Calculate the optimal offsets\n",
    "C_x, C_y = calculate_corrections(differences)\n",
    "print(f\"Optimal offsets: C_x = {C_x}, C_y = {C_y}\")\n",
    "\n",
    "end_time = time.time()  # Record the end time of processing\n",
    "total_time = end_time - start_time  # Calculate the total processing time\n",
    "average_time_per_image = total_time / len(os.listdir(TESTDIR_IMGS))  # Calculate the average processing time per image\n",
    "print(f\"Average time per image: {average_time_per_image:.2f} seconds\")  # Print the average time per image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ae925",
   "metadata": {},
   "source": [
    "## 4.4 First Approach Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd385442",
   "metadata": {},
   "source": [
    "### Hyperparameters and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a71ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths for saving calibration matrices and statistics\n",
    "SAVEDIR = '../data/calibration_matrixes/'  # Directory to save calibration matrices\n",
    "STATSDIR = os.path.join(SAVEDIR, 'feature_stats.json')  # Path to save feature statistics in JSON format\n",
    "\n",
    "# Define directories for test data and labels\n",
    "TESTDIR_DEPTH = '../data/imgs_depth/'  # Directory containing depth images for testing\n",
    "TESTDIR_LABELSGT = '../data/labels_gt_RF/'  # Directory containing ground truth labels for testing\n",
    "\n",
    "# Define directories and files for saving results and base dataset\n",
    "SAVEFILE = '../data'  # Directory to save various data files\n",
    "BASE_DATASET = '../data/images-rgb-C'  # Base directory containing RGB images of dataset\n",
    "\n",
    "# Define a threshold value for area\n",
    "AREA_TRESHOLD = 8000  # Threshold value for area filtering\n",
    "\n",
    "# Define constants for calibration (camera parameters or similar)\n",
    "C_x = -5.600124724948292  # Calibration constant for x-coordinate\n",
    "C_y = -10.20561848357434  # Calibration constant for y-coordinate\n",
    "\n",
    "# Define file paths for saving results\n",
    "FILE_PATH_POINTWISE = '../data/results_pointwise.csv'  # Path to save pointwise results in CSV format\n",
    "FILE_PATH = '../data/results.csv'  # Path to save general results in CSV format\n",
    "SAVEFOLDER = '../results/'  # Directory to save generated graphs\n",
    "\n",
    "# Define a mapping between corruption types and their respective function names\n",
    "corruption_function_map = {\n",
    "    'c0': 'gaussian_noise',           # Corruption type 'c0' maps to Gaussian noise\n",
    "    'c1': 'shot_noise',               # Corruption type 'c1' maps to Shot noise\n",
    "    'c2': 'impulse_noise',            # Corruption type 'c2' maps to Impulse noise\n",
    "    'c4': 'glass_blur',               # Corruption type 'c4' maps to Glass blur\n",
    "    'c5': 'motion_blur',              # Corruption type 'c5' maps to Motion blur\n",
    "    'c6': 'fog',                      # Corruption type 'c6' maps to Fog\n",
    "    'c7': 'brightness',               # Corruption type 'c7' maps to Brightness adjustment\n",
    "    'c8': 'contrast',                 # Corruption type 'c8' maps to Contrast adjustment\n",
    "    'c9': 'elastic_transform',        # Corruption type 'c9' maps to Elastic transform\n",
    "    'c10': 'speckle_noise',           # Corruption type 'c10' maps to Speckle noise\n",
    "    'c11': 'gaussian_blur',           # Corruption type 'c11' maps to Gaussian blur\n",
    "    'c12': 'spatter',                 # Corruption type 'c12' maps to Spatter\n",
    "    'c13': 'saturate'                 # Corruption type 'c13' maps to Saturate\n",
    "}\n",
    "\n",
    "# Define colors associated with each corruption type for visualization purposes\n",
    "colors = {\n",
    "    'gaussian_noise': 'orange',       # Color for Gaussian noise is orange\n",
    "    'shot_noise': 'blue',             # Color for Shot noise is blue\n",
    "    'impulse_noise': 'green',         # Color for Impulse noise is green\n",
    "    'glass_blur': 'purple',           # Color for Glass blur is purple\n",
    "    'motion_blur': 'brown',           # Color for Motion blur is brown\n",
    "    'fog': 'pink',                    # Color for Fog is pink\n",
    "    'brightness': 'gray',             # Color for Brightness adjustment is gray\n",
    "    'contrast': 'cyan',               # Color for Contrast adjustment is cyan\n",
    "    'elastic_transform': 'magenta',   # Color for Elastic transform is magenta\n",
    "    'speckle_noise': 'yellow',        # Color for Speckle noise is yellow\n",
    "    'gaussian_blur': 'black',         # Color for Gaussian blur is black\n",
    "    'spatter': 'lime',                # Color for Spatter is lime\n",
    "    'saturate': 'navy'                # Color for Saturate is navy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ac11f",
   "metadata": {},
   "source": [
    "### Precompute matrix for a faster Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute camera matrix and distortion mappings if possible\n",
    "\n",
    "# Get the path of a sample image from the test directory\n",
    "sample_image_path = os.path.join(TESTDIR_IMGS, os.listdir(TESTDIR_IMGS)[0])\n",
    "\n",
    "# Read the sample image using OpenCV\n",
    "sample_image = cv2.imread(sample_image_path)\n",
    "\n",
    "# Get the height and width of the sample image\n",
    "h, w = sample_image.shape[:2]\n",
    "\n",
    "# Compute the optimal new camera matrix given the original camera matrix, \n",
    "# distortion coefficients, and image size. The free scaling parameter is set to 1.\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(cam.mtx, cam.dist, (w, h), 1, (w, h))\n",
    "\n",
    "# Compute the undistortion and rectification transformation map\n",
    "# `mapx` and `mapy` are the x and y coordinates of the undistorted image\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(cam.mtx, cam.dist, None, newcameramtx, (w, h), 5)\n",
    "\n",
    "# Define a resizing transformation to resize the image to 1920x1080 using linear interpolation\n",
    "post_predict_resize = A.Resize(height=1080, width=1920, interpolation=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65041f56",
   "metadata": {},
   "source": [
    "### Get data into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "differences = []\n",
    "results = []\n",
    "pointwise_result = []\n",
    "\n",
    "# Sweep through sigma values from 1 to 10 with a step of 2\n",
    "for sigma in range(1, 11, 2):\n",
    "    print(f'Sigma: {sigma}')\n",
    "    # Iterate through different types of corruption in the dataset\n",
    "    for corruption in os.listdir(BASE_DATASET):\n",
    "        corruption_path = os.path.join(BASE_DATASET, corruption)\n",
    "        # Iterate through severity levels of each corruption type\n",
    "        for severity in os.listdir(corruption_path):\n",
    "            images_path = os.path.join(corruption_path, severity, 'imgs')\n",
    "            NON_DETECTED = 0 \n",
    "            TOTAL_PIECES = len(os.listdir(images_path))\n",
    "            differences = []\n",
    "            start_time = time.time()\n",
    "            # Process each image in the current path\n",
    "            for image_file in os.listdir(images_path):\n",
    "                image = cv2.imread(os.path.join(images_path, image_file))\n",
    "                depth = np.load(os.path.join(TESTDIR_DEPTH, image_file.replace('.jpg', '.npy')))\n",
    "                labels_gt = read_labels(os.path.join(TESTDIR_LABELSGT, image_file.replace('.jpg', '.txt')))\n",
    "                \n",
    "                # Apply perspective warp to the image\n",
    "                image = cv2.warpPerspective(image, M, (w, h))\n",
    "                \n",
    "                # Convert image to PIL format, apply transformations, and predict with the model\n",
    "                image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                transformed = test_transforms(image=np.array(image))\n",
    "                image = transformed[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    prediction = model(image)\n",
    "                prediction = torch.sigmoid(prediction)\n",
    "                prediction = (prediction > 0.5).float()\n",
    "\n",
    "                # Resize the prediction and convert to tensor\n",
    "                prediction = prediction.squeeze().cpu().numpy()\n",
    "                resized_prediction = post_predict_resize(image=prediction)['image']\n",
    "                tensor_prediction = torch.from_numpy(resized_prediction).unsqueeze(0)\n",
    "            \n",
    "                # Post-process the prediction\n",
    "                tensor_prediction = postprocess(tensor_prediction, AREA_TRESHOLD)    \n",
    "                \n",
    "                # Get features of detected pieces\n",
    "                pieces_features = get_pieces_features(tensor_prediction)\n",
    "                \n",
    "                # Filter objects not similar to images based on sigma\n",
    "                pieces_features = filter_pieces(STATSDIR, pieces_features, sigma)\n",
    "                save_path = os.path.join(PRED_TESTDIR, f\"{image_file.split('.')[0]}.png\")\n",
    "                \n",
    "                if len(pieces_features) != 0:\n",
    "                    for piece in pieces_features: \n",
    "                        # Get data for each detected piece\n",
    "                        center = piece['centroid']\n",
    "                        radius = piece['radius']\n",
    "                        # Transform pixel coordinates back to the original image\n",
    "                        new_pixel = np.dot(np.linalg.inv(M), np.array([[center[0]], [center[1]], [1]]))\n",
    "                        center = [int(new_pixel[0][0] / new_pixel[2][0]), int(new_pixel[1][0] / new_pixel[2][0])]\n",
    "                        \n",
    "                        # Get depth of the pixel\n",
    "                        pixel_depth = depth[center[1], center[0]]\n",
    "                        \n",
    "                        # Transform 2D pixel to 3D camera coordinates\n",
    "                        xcam, ycam, zcam = cam.intrinsic_trans(center, pixel_depth, cam.mtx)\n",
    "\n",
    "                        # Transform camera coordinates to robot base frame\n",
    "                        p_bt = np.dot(T_bc, np.array([[xcam], [ycam], [zcam], [1]]))  # Position of the object in robot base frame\n",
    "\n",
    "                        # Create pick position for robot\n",
    "                        xyz = np.array([p_bt[0][0], p_bt[1][0], p_bt[2][0]]) \n",
    "                        xyz[2] = 5\n",
    "                        \n",
    "                        # Predicted and ground truth coordinates\n",
    "                        x_pred, y_pred = xyz[0] + C_x, xyz[1] + C_y\n",
    "                        x_gt, y_gt = labels_gt[0], labels_gt[1]\n",
    "                        \n",
    "                        # Save the differences\n",
    "                        differences.append((x_gt - x_pred, y_gt - y_pred))\n",
    "                        r_value_pointwise = math.sqrt((x_gt - x_pred) ** 2 + (y_gt - y_pred) ** 2)\n",
    "                        c = corruption_function_map[corruption]\n",
    "                        s = severity\n",
    "                        pointwise_result.append([sigma, c, s, r_value_pointwise])\n",
    "                        \n",
    "                else:\n",
    "                    NON_DETECTED += 1\n",
    "\n",
    "            # Calculate and store the errors if there are any\n",
    "            errors_np = np.array(differences)\n",
    "            if len(errors_np) != 0:     \n",
    "                r_values = np.sqrt(np.sum(errors_np ** 2, axis=1))\n",
    "\n",
    "                # Calculate mean and standard deviation of errors\n",
    "                mean_r = np.mean(r_values)\n",
    "                std_r = np.std(r_values)\n",
    "\n",
    "                # Create a tuple with mean and standard deviation\n",
    "                result = (mean_r, std_r)\n",
    "                percentage = (1 - (NON_DETECTED / TOTAL_PIECES)) * 100\n",
    "                c = corruption_function_map[corruption]\n",
    "                s = severity\n",
    "                results.append([sigma, c, s, result[0], result[1], percentage])\n",
    "            else:\n",
    "                s = severity\n",
    "                c = corruption_function_map[corruption]\n",
    "                percentage = (1 - (NON_DETECTED / TOTAL_PIECES)) * 100\n",
    "                results.append([sigma, c, s, None, None, percentage])\n",
    "\n",
    "# Save pointwise results to a CSV file\n",
    "df_pointwise = pd.DataFrame(pointwise_result, columns=['sigma', 'corruption_name', 'severity', 'error'])\n",
    "df_pointwise.to_csv(os.path.join(SAVEFILE, 'results_pointwise.csv'), index=False)\n",
    "\n",
    "# Create a pandas DataFrame with the results\n",
    "df = pd.DataFrame(results, columns=['sigma', 'corruption_name', 'severity', 'mean_error', 'std_error', '%detected'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(os.path.join(SAVEFILE, 'results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6993df",
   "metadata": {},
   "source": [
    "### CSV to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Load another CSV file for pointwise data\n",
    "data_pointwise = pd.read_csv(FILE_PATH_POINTWISE)\n",
    "\n",
    "# Separate the data into blocks based on unique values of sigma\n",
    "blocks = {sigma: data[data['sigma'] == sigma] for sigma in data['sigma'].unique()}\n",
    "# Separate the pointwise data into blocks based on unique values of sigma\n",
    "blocks_pointwise = {sigma: data_pointwise[data_pointwise['sigma'] == sigma] for sigma in data_pointwise['sigma'].unique()}\n",
    "\n",
    "# Define a list of sigma values to iterate over\n",
    "sigma_list = list(range(1, 10, 2))\n",
    "\n",
    "# Loop through each block\n",
    "for i in range(len(blocks)):\n",
    "    sigma = sigma_list[i]\n",
    "\n",
    "    # Create a summary to check the number of unique corruption names and the number of unique severities within each corruption name for each block\n",
    "    block_example = blocks[sigma]  # Change the sigma value as needed\n",
    "\n",
    "    # Create improved x-axis labels without the extra 's' prefix\n",
    "    # Ensure all combinations are represented\n",
    "    corruption_names = list(corruption_function_map.values())\n",
    "    severity_levels = [f's{i}' for i in range(1, 6)]\n",
    "\n",
    "    # Calculate values for the histogram of the percentage of detected pieces\n",
    "    data_for_histogram = []\n",
    "\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            subset = block_example[(block_example['corruption_name'] == corruption_name) & (block_example['severity'] == severity)]\n",
    "            if not subset.empty:\n",
    "                detected_value = subset['%detected'].values[0]\n",
    "                data_for_histogram.append(detected_value)\n",
    "            else:\n",
    "                data_for_histogram.append(0)\n",
    "\n",
    "    # Generate colors for each bar in the histogram\n",
    "    bar_colors = []\n",
    "    for corruption_name in corruption_names:\n",
    "        bar_colors.extend([colors[corruption_name]] * len(severity_levels))\n",
    "\n",
    "    # Create the histogram plot\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    # Y-axis values (% detected)\n",
    "    y_values_detected = np.array(data_for_histogram)\n",
    "\n",
    "    # Generate the histogram with colors and adjust margins\n",
    "    bar_width = 0.8  # Adjust the width of the bars to leave space between blocks\n",
    "    positions = np.arange(len(y_values_detected)) * 1.1  # Adjust positions to leave space between blocks\n",
    "\n",
    "    plt.bar(positions, y_values_detected, color=bar_colors, width=bar_width)\n",
    "\n",
    "    # Adjust x-axis labels\n",
    "    severity_labels = []\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            severity_labels.append(f'{severity}')\n",
    "\n",
    "    plt.xticks(ticks=positions, labels=severity_labels, rotation=90)\n",
    "\n",
    "    # Set y-axis range\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    # Set x-axis range to occupy the whole graph\n",
    "    plt.xlim(-0.5, positions[-1] + 0.5)\n",
    "\n",
    "    # Add legend to identify colors\n",
    "    legend_labels = [f'{corruption_function_map[c]} = {c}' for c in corruption_function_map]\n",
    "    handles = [plt.Line2D([0], [0], color=colors[corruption_function_map[c]], lw=4) for c in corruption_function_map]\n",
    "\n",
    "    plt.legend(handles, legend_labels, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Set labels and title for the plot\n",
    "    plt.ylabel('Detected Percentage')\n",
    "    plt.title(f'Detected Percentage vs Severity and Corruption Name for Sigma = {sigma}')\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    # Save the plot instead of displaying it\n",
    "    plt.savefig(f'{SAVEFOLDER}histogram_sigma_{sigma}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Loop through each pointwise block\n",
    "for i in range(len(blocks_pointwise)):   \n",
    "    sigma = sigma_list[i]\n",
    "\n",
    "    # Create a summary to check the number of unique corruption names and the number of unique severities within each corruption name for each block\n",
    "    block_example = blocks_pointwise[sigma]  # Change the sigma value as needed\n",
    "\n",
    "    # Calculate values for the boxplot using percentiles\n",
    "    data_for_boxplot = []\n",
    "    corruption_names = list(corruption_function_map.values())\n",
    "    severity_levels = [f's{i}' for i in range(1, 6)]\n",
    "\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            subset = block_example[(block_example['corruption_name'] == corruption_name) & (block_example['severity'] == severity)]\n",
    "            if not subset.empty:\n",
    "                percentiles = np.percentile(subset['error'], [25, 50, 75])\n",
    "                min_val = subset['error'].min()\n",
    "                max_val = subset['error'].max()\n",
    "                data_for_boxplot.append([min_val, percentiles[0], percentiles[1], percentiles[2], max_val])\n",
    "            else:\n",
    "                data_for_boxplot.append([np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "\n",
    "    # Generate colors for each box in the boxplot\n",
    "    box_colors = []\n",
    "    for corruption_name in corruption_names:\n",
    "        box_colors.extend([colors[corruption_name]] * len(severity_levels))\n",
    "\n",
    "    # Create the boxplot\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    box = plt.boxplot(data_for_boxplot, vert=True, patch_artist=True, whis=[0, 100])\n",
    "\n",
    "    # Apply colors to each box in the boxplot\n",
    "    for patch, color in zip(box['boxes'], box_colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    # Adjust x-axis labels\n",
    "    severity_labels = []\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            severity_labels.append(f'{severity}')\n",
    "\n",
    "    plt.xticks(ticks=np.arange(1, len(severity_labels) + 1), labels=severity_labels, rotation=90)\n",
    "\n",
    "    # Add legend to identify colors\n",
    "    legend_labels = [f'{corruption_function_map[c]} = {c}' for c in corruption_function_map]\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, color=colors[corruption_function_map[c]]) for c in corruption_function_map]\n",
    "\n",
    "    plt.legend(handles, legend_labels, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Set y-axis label and title for the plot\n",
    "    plt.ylabel('Piece picking uncertainty (mm)')\n",
    "    plt.title(f'Boxplot of Picking uncertainty (mm) vs Severity of Corruption Name for Sigma = {sigma}')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Set y-axis limit\n",
    "    plt.ylim(0, 10)\n",
    "    plt.savefig(f'{SAVEFOLDER}boxplot_sigma_{sigma}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1230937",
   "metadata": {},
   "source": [
    "### 3.6.2 Second Approach (Training an MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c37a5b",
   "metadata": {},
   "source": [
    "#### Data Pths and Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed7afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute camera matrix and distortion mappings if possible\n",
    "# This assumes all images have the same dimension, which should be validated beforehand\n",
    "SAVEDIR = '../data/calibration_matrixes/'\n",
    "STATSDIR= os.path.join(SAVEDIR, 'feature_stats.json')\n",
    "\n",
    "TESTDIR_IMGS = '../data/images_rgb'\n",
    "TESTDIR_DEPTH = '../data/imgs_depth/'\n",
    "TESTDIR_LABELSGT = '../data/labels_gt_RF/'\n",
    "\n",
    "BASE_DATASET = '../data/images-rgb-C'\n",
    "\n",
    "SIGMA = 5\n",
    "AREA_TRESHOLD = 9000\n",
    "NON_DETECTED_PIECES=0\n",
    "\n",
    "x_wc_list = []  \n",
    "y_gt_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3cf967",
   "metadata": {},
   "source": [
    "#### Get GT labels, Warped Camera Frame (Input) and Robot Frame (Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ed13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in os.listdir(TESTDIR_IMGS):\n",
    "    \n",
    "    image = cv2.imread(os.path.join(TESTDIR_IMGS, image_file))\n",
    "\n",
    "    depth = np.load(os.path.join(TESTDIR_DEPTH,image_file.replace('.jpg', '.npy')))\n",
    "    labels_gt = read_labels(os.path.join(TESTDIR_LABELSGT,image_file.replace('.jpg', '.txt')))\n",
    "    \n",
    "    #image = cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n",
    "    image = cv2.warpPerspective(image, M, (w, h))\n",
    "    \n",
    "    # Convert image to PIL, apply transforms, and predict with the model\n",
    "    image= Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    transformed = test_transforms(image=np.array(image))\n",
    "    image = transformed[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(image)\n",
    "    prediction = torch.sigmoid(prediction)\n",
    "    prediction = (prediction > 0.5).float()\n",
    "\n",
    "    # Resize prediction and save\n",
    "    prediction = prediction.squeeze().cpu().numpy()\n",
    "    resized_prediction = post_predict_resize(image=prediction)['image']\n",
    "    tensor_prediction = torch.from_numpy(resized_prediction).unsqueeze(0)\n",
    "   \n",
    "    #Postprocessing\n",
    "    tensor_prediction = postprocess(tensor_prediction, AREA_TRESHOLD)    \n",
    "    \n",
    "    #Get Pieces features\n",
    "    pieces_features = get_pieces_features(tensor_prediction)\n",
    "    \n",
    "    #Filter objects not similar to images\n",
    "    pieces_features = filter_pieces(STATSDIR , pieces_features, SIGMA)\n",
    "    save_path = os.path.join(PRED_TESTDIR, f\"{image_file.split('.')[0]}.png\")\n",
    "    #save_annotated_image(tensor_prediction, save_path, pieces_features)\n",
    "    \n",
    "    if len(pieces_features)!=0:\n",
    "        for piece in pieces_features: \n",
    "            #Get Data\n",
    "            center = piece['centroid']\n",
    "            radius = piece['radius']\n",
    "            # Transform pixel on warped image back to original image\n",
    "            new_pixel = np.dot(np.linalg.inv(M), np.array([[center[0]], [center[1]], [1]]))\n",
    "            center = [int(new_pixel[0][0]/new_pixel[2][0]), int(new_pixel[1][0]/new_pixel[2][0])]\n",
    "            \n",
    "            ## Get pixel depth \n",
    "            pixel_depth = depth[center[1], center[0]]\n",
    "            \n",
    "            x_wc = center[0]\n",
    "            y_wc = center[1]\n",
    "            z_wc = pixel_depth \n",
    "\n",
    "            x_wc_list.append((x_wc,y_wc,z_wc))\n",
    "\n",
    "            x_gt, y_gt, z_gt = labels_gt[0], labels_gt[1] , labels_gt[2]\n",
    "            \n",
    "            y_gt_list.append((x_gt,y_gt,z_gt))\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(f'Nothing detected')  \n",
    "        NON_DETECTED_PIECES +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "X = np.array(x_wc_list)\n",
    "y = np.array(y_gt_list)\n",
    "\n",
    "# Normalize the data\n",
    "scaler_X = StandardScaler()  # Initialize a StandardScaler for X\n",
    "scaler_y = StandardScaler()  # Initialize a StandardScaler for y\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)  # Fit the scaler to X and transform X\n",
    "y_scaled = scaler_y.fit_transform(y)  # Fit the scaler to y and transform y\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)  # Convert the training data for X to a float32 tensor\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)    # Convert the testing data for X to a float32 tensor\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Convert the training data for y to a float32 tensor\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e27dd4",
   "metadata": {},
   "source": [
    "#### MLP Hyperparameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to explore\n",
    "NINPUT = 3  # Number of input features\n",
    "NOUTPUT = 3  # Number of output features\n",
    "NHIDDEN = [5, 10, 15, 20, 25]  # List of hidden layer sizes to explore\n",
    "ACTIVATION = [nn.ReLU(), nn.Sigmoid(), nn.Tanh()]  # List of activation functions to explore\n",
    "LEARNING_RATE = [0.01, 0.001, 0.0001, 0.00001]  # List of learning rates to explore\n",
    "NUM_EPOCHS = 1000  # Number of epochs for training\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(model, criterion, optimizer, num_epochs, X_train, y_train, X_test, y_test, scaler_y):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        optimizer.zero_grad()  # Clear the gradients\n",
    "        outputs = model(X_train)  # Forward pass\n",
    "        loss = criterion(outputs, y_train)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the weights\n",
    "        \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test)  # Make predictions\n",
    "        # Convert predictions and labels back to their original scale\n",
    "        predictions_unscaled = scaler_y.inverse_transform(predictions.numpy())\n",
    "        y_test_unscaled = scaler_y.inverse_transform(y_test.numpy())\n",
    "        # Calculate Euclidean distances\n",
    "        distances = np.sqrt(np.sum((y_test_unscaled - predictions_unscaled)**2, axis=1))\n",
    "        average_distance = np.mean(distances)  # Calculate the average distance\n",
    "    return average_distance\n",
    "\n",
    "# Hyperparameter sweep\n",
    "best_distance = float('inf')  # Initialize the best distance with infinity\n",
    "best_params = {}  # Dictionary to store the best hyperparameters\n",
    "\n",
    "for hidden in NHIDDEN:\n",
    "    for activation in ACTIVATION:\n",
    "        for lr in LEARNING_RATE:\n",
    "            model = nn.Sequential(\n",
    "                nn.Linear(NINPUT, hidden),  # Input to first hidden layer\n",
    "                activation,  # Activation function\n",
    "                nn.Linear(hidden, hidden),  # Hidden to hidden layer\n",
    "                activation,  # Activation function\n",
    "                nn.Linear(hidden, NOUTPUT)  # Hidden to output layer\n",
    "            )\n",
    "            criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)  # Adam optimizer with current learning rate\n",
    "            \n",
    "            # Train and evaluate the model\n",
    "            avg_distance = train_and_evaluate(model, criterion, optimizer, NUM_EPOCHS, \n",
    "                                              X_train_tensor, y_train_tensor, \n",
    "                                              X_test_tensor, y_test_tensor, scaler_y)\n",
    "            \n",
    "            # Print current hyperparameters and average distance\n",
    "            print(f'Hidden: {hidden}, Activation: {activation}, Learning Rate: {lr}, Average Distance: {avg_distance:.4f}')\n",
    "            \n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            with torch.no_grad():\n",
    "                predictions = model(X_test_tensor)  # Make predictions on the test set\n",
    "                loss = criterion(predictions, y_test_tensor)  # Compute the test loss\n",
    "                print(f'Test Loss: {loss.item():.4f}')\n",
    "    \n",
    "                # Convert predictions and labels back to their original scale\n",
    "                predictions_unscaled = scaler_y.inverse_transform(predictions.numpy())\n",
    "                y_test_unscaled = scaler_y.inverse_transform(y_test)\n",
    "    \n",
    "                # Calculate Mean Squared Error (MSE) on the original scale\n",
    "                mse = mean_squared_error(y_test_unscaled, predictions_unscaled)\n",
    "                print(f'Test MSE (original scale): {mse:.4f}')\n",
    "    \n",
    "                # Calculate Euclidean distances\n",
    "                distances = np.sqrt(np.sum((y_test_unscaled - predictions_unscaled)**2, axis=1))\n",
    "                average_distance = np.mean(distances)  # Calculate the average distance\n",
    "            \n",
    "            # Print current hyperparameters and average distance\n",
    "            print(f'Hidden: {hidden}, Activation: {activation}, Learning Rate: {lr}, Average Distance: {avg_distance:.4f}')\n",
    "            \n",
    "            # Update the best parameters if the current average distance is lower\n",
    "            if avg_distance < best_distance:\n",
    "                best_distance = avg_distance\n",
    "                best_params = {\n",
    "                    'hidden': hidden,\n",
    "                    'activation': activation,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "\n",
    "# Print the best hyperparameters and the best average distance\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Average Distance: {best_distance:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50f42b",
   "metadata": {},
   "source": [
    "#### Optimal Hyperparameter Model Training and Evaluation in the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of input features\n",
    "NINPUT = 3\n",
    "\n",
    "# Define the number of output features\n",
    "NOUTPUT = 3\n",
    "\n",
    "# Define the number of neurons in the hidden layers\n",
    "NHIDDEN = 25\n",
    "\n",
    "# Set the activation function to Tanh\n",
    "ACTIVATION = nn.Tanh()\n",
    "\n",
    "# Define the learning rate for the optimizer\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Set the number of epochs for training\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "\n",
    "# Define the model with the best hyperparameters\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(NINPUT, NHIDDEN),  # Input layer to first hidden layer\n",
    "    ACTIVATION,                 # Activation function\n",
    "    nn.Linear(NHIDDEN, NHIDDEN), # First hidden layer to second hidden layer\n",
    "    ACTIVATION,                 # Activation function\n",
    "    nn.Linear(NHIDDEN, NOUTPUT) # Second hidden layer to output layer\n",
    ")\n",
    "\n",
    "# Set the loss function to Mean Squared Error\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Set the optimizer to Adam with the defined learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    outputs = model(X_train_tensor)  # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "    loss = criterion(outputs, y_train_tensor)  # Compute the loss\n",
    "    loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "    optimizer.step()  # Update model parameters\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:  # Print the loss every 100 epochs\n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    predictions = model(X_test_tensor)  # Compute predicted outputs for the test set\n",
    "    # Convert the predictions and the labels back to their original scale\n",
    "    predictions_unscaled = scaler_y.inverse_transform(predictions.numpy())\n",
    "    y_test_unscaled = scaler_y.inverse_transform(y_test_tensor.numpy())\n",
    "    \n",
    "    # Calculate the Euclidean distances between the true and predicted values\n",
    "    distances = np.sqrt(np.sum((y_test_unscaled - predictions_unscaled)**2, axis=1))\n",
    "    average_distance = np.mean(distances)  # Compute the average distance\n",
    "\n",
    "print(f'Average Euclidean Distance: {average_distance:.4f}')\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), '../models/mlp_checkpoint.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83697aea",
   "metadata": {},
   "source": [
    "## 4.5 Evaluation of the Second Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd4acb",
   "metadata": {},
   "source": [
    "#### Model Initialization with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of input features\n",
    "NINPUT = 3\n",
    "\n",
    "# Define the number of output features\n",
    "NOUTPUT = 3\n",
    "\n",
    "# Define the number of neurons in the hidden layers\n",
    "NHIDDEN = 25\n",
    "\n",
    "# Set the activation function to Tanh\n",
    "ACTIVATION = nn.Tanh()\n",
    "\n",
    "model_mlp = nn.Sequential(\n",
    "    nn.Linear(NINPUT, NHIDDEN),\n",
    "    ACTIVATION,\n",
    "    nn.Linear(NHIDDEN, NHIDDEN),\n",
    "    ACTIVATION,\n",
    "    nn.Linear(NHIDDEN, NOUTPUT)\n",
    ")\n",
    "model_mlp.load_state_dict(torch.load('mlp_checkpoint.pth.tar'))\n",
    "\n",
    "# Model initialization with specified input and output channels\n",
    "model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "load_checkpoint(torch.load(CHECKPOINT_PATH ), model)\n",
    "model.eval()  # Set the model to evaluation mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72e3a6",
   "metadata": {},
   "source": [
    "#### Used For Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in os.listdir(TESTDIR_IMGS):\n",
    "    \n",
    "    image = cv2.imread(os.path.join(TESTDIR_IMGS, image_file))\n",
    "\n",
    "    depth = np.load(os.path.join(TESTDIR_DEPTH,image_file.replace('.jpg', '.npy')))\n",
    "    labels_gt = read_labels(os.path.join(TESTDIR_LABELSGT,image_file.replace('.jpg', '.txt')))\n",
    "    \n",
    "    #image = cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n",
    "    image = cv2.warpPerspective(image, M, (w, h))\n",
    "    \n",
    "    # Convert image to PIL, apply transforms, and predict with the model\n",
    "    image= Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    transformed = test_transforms(image=np.array(image))\n",
    "    image = transformed[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(image)\n",
    "    prediction = torch.sigmoid(prediction)\n",
    "    prediction = (prediction > 0.5).float()\n",
    "\n",
    "    # Resize prediction and save\n",
    "    prediction = prediction.squeeze().cpu().numpy()\n",
    "    resized_prediction = post_predict_resize(image=prediction)['image']\n",
    "    tensor_prediction = torch.from_numpy(resized_prediction).unsqueeze(0)\n",
    "   \n",
    "    #Postprocessing\n",
    "    tensor_prediction = postprocess(tensor_prediction, AREA_TRESHOLD)    \n",
    "    \n",
    "    #Get Pieces features\n",
    "    pieces_features = get_pieces_features(tensor_prediction)\n",
    "    \n",
    "    #Filter objects not similar to images\n",
    "    pieces_features = filter_pieces(STATSDIR , pieces_features, SIGMA)\n",
    "    save_path = os.path.join(PRED_TESTDIR, f\"{image_file.split('.')[0]}.png\")\n",
    "    #save_annotated_image(tensor_prediction, save_path, pieces_features)\n",
    "    \n",
    "    if len(pieces_features)!=0:\n",
    "        for piece in pieces_features: \n",
    "            #Get Data\n",
    "            center = piece['centroid']\n",
    "            radius = piece['radius']\n",
    "            # Transform pixel on warped image back to original image\n",
    "            new_pixel = np.dot(np.linalg.inv(M), np.array([[center[0]], [center[1]], [1]]))\n",
    "            center = [int(new_pixel[0][0]/new_pixel[2][0]), int(new_pixel[1][0]/new_pixel[2][0])]\n",
    "            \n",
    "            ## Get pixel depth \n",
    "            pixel_depth = depth[center[1], center[0]]\n",
    "            \n",
    "            x_wc = center[0]\n",
    "            y_wc = center[1]\n",
    "            z_wc = pixel_depth \n",
    "            # Preparar entrada para el modelo MLP\n",
    "            input_mlp_raw = np.array([[x_wc, y_wc, z_wc]])  # Convertir a formato numpy array y agregar una dimensión\n",
    "            input_mlp_scaled = scaler_X.transform(input_mlp_raw)  # Aplicar el escalado\n",
    "            input_mlp = torch.tensor(input_mlp_scaled, dtype=torch.float32)  # Convertir a tensor\n",
    "            with torch.no_grad():\n",
    "                output_mlp = model_mlp(input_mlp)\n",
    "            output_mlp_unscaled = scaler_y.inverse_transform(output_mlp.numpy().reshape(1, -1)).squeeze()\n",
    "            x_pred, y_pred, z_pred = output_mlp_unscaled\n",
    "            x_gt, y_gt, z_gt = labels_gt[0], labels_gt[1] , labels_gt[2]\n",
    "            \n",
    "            print(f'Image: {image_file}')\n",
    "            print(f'Warped Camera Frame: ({x_pred},{y_pred},{z_pred})')\n",
    "            print(f'Robot Frame: ({x_gt},{y_gt},{z_gt})')\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(f'Nothing detected')  \n",
    "        NON_DETECTED_PIECES +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0e186",
   "metadata": {},
   "source": [
    "#### Hyperparameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to directories and files\n",
    "SAVEDIR = '../data/calibration_matrixes/'\n",
    "STATSDIR = os.path.join(SAVEDIR, 'feature_stats.json')\n",
    "\n",
    "TESTDIR_DEPTH = '../data/imgs_depth/'\n",
    "TESTDIR_LABELSGT = '../data/labels_gt/'\n",
    "SAVEFILE = '../data'\n",
    "BASE_DATASET = '../data/images-rgb-C'\n",
    "AREA_TRESHOLD = 8000\n",
    "\n",
    "C_x = -5.600124724948292\n",
    "C_y = -10.20561848357434\n",
    "SIGMA = 9 \n",
    "\n",
    "FILE_PATH_POINTWISE = '../data/results_pointwise_approach2.csv'\n",
    "FILE_PATH = '../data/results_approach2.csv'\n",
    "SAVEFOLDER = '../results/boxplot_histogram_model_mlp/'\n",
    "\n",
    "SCALER_X_PATH = '../data/calibration_matrixes/scaler_X.pkl'\n",
    "SCALER_Y_PATH= '../data/calibration_matrixes/scaler_Y.pkl'\n",
    "\n",
    "scaler_X = joblib.load(SCALER_X_PATH)\n",
    "scaler_Y = joblib.load(SCALER_Y_PATH)\n",
    "\n",
    "# Mapping of corruption types\n",
    "corruption_function_map = {\n",
    "    'c0': 'gaussian_noise',\n",
    "    'c1': 'shot_noise',\n",
    "    'c2': 'impulse_noise',\n",
    "    'c4': 'glass_blur',\n",
    "    'c5': 'motion_blur',\n",
    "    'c6': 'fog',\n",
    "    'c7': 'brightness',\n",
    "    'c8': 'contrast',\n",
    "    'c9': 'elastic_transform',\n",
    "    'c10': 'speckle_noise',\n",
    "    'c11': 'gaussian_blur',\n",
    "    'c12': 'spatter',\n",
    "    'c13': 'saturate'\n",
    "}\n",
    "\n",
    "# Colors associated with each corruption type for visualization\n",
    "colors = {\n",
    "    'gaussian_noise': 'orange',\n",
    "    'shot_noise': 'blue',\n",
    "    'impulse_noise': 'green',\n",
    "    'glass_blur': 'purple',\n",
    "    'motion_blur': 'brown',\n",
    "    'fog': 'pink',\n",
    "    'brightness': 'gray',\n",
    "    'contrast': 'cyan',\n",
    "    'elastic_transform': 'magenta',\n",
    "    'speckle_noise': 'yellow',\n",
    "    'gaussian_blur': 'black',\n",
    "    'spatter': 'lime',\n",
    "    'saturate': 'navy'\n",
    "}\n",
    "\n",
    "# Functions and processing logic would be implemented below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1915bc8c",
   "metadata": {},
   "source": [
    "#### Prediction CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "differences = []\n",
    "results = []\n",
    "pointwise_result = []\n",
    "\n",
    "# Iterate over a range of sigma values\n",
    "for sigma in range(1, 11, 2):\n",
    "    print(f'Sigma: {sigma}')\n",
    "    # Iterate over each corruption type in the dataset\n",
    "    for corruption in os.listdir(BASE_DATASET):\n",
    "        corruption_path = os.path.join(BASE_DATASET, corruption)\n",
    "        # Iterate over each severity level of the corruption\n",
    "        for severity in os.listdir(corruption_path):\n",
    "            images_path = os.path.join(corruption_path, severity, 'imgs')\n",
    "            NON_DETECTED = 0\n",
    "            TOTAL_PIECES = len(os.listdir(images_path))\n",
    "            differences = []\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Iterate over each image in the specified path\n",
    "            for image_file in os.listdir(images_path):\n",
    "                image = cv2.imread(os.path.join(images_path, image_file))\n",
    "                depth = np.load(os.path.join(TESTDIR_DEPTH, image_file.replace('.jpg', '.npy')))\n",
    "                labels_gt = read_labels(os.path.join(TESTDIR_LABELSGT, image_file.replace('.jpg', '.txt')))\n",
    "                \n",
    "                # Apply perspective transformation to the image\n",
    "                image = cv2.warpPerspective(image, M, (w, h))\n",
    "                \n",
    "                # Convert image to PIL format, apply transformations, and predict with the model\n",
    "                image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                transformed = test_transforms(image=np.array(image))\n",
    "                image = transformed[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    prediction = model(image)\n",
    "                prediction = torch.sigmoid(prediction)\n",
    "                prediction = (prediction > 0.5).float()\n",
    "\n",
    "                # Resize prediction and save\n",
    "                prediction = prediction.squeeze().cpu().numpy()\n",
    "                resized_prediction = post_predict_resize(image=prediction)['image']\n",
    "                tensor_prediction = torch.from_numpy(resized_prediction).unsqueeze(0)\n",
    "            \n",
    "                # Postprocessing\n",
    "                tensor_prediction = postprocess(tensor_prediction, AREA_TRESHOLD)    \n",
    "                \n",
    "                # Get pieces features\n",
    "                pieces_features = get_pieces_features(tensor_prediction)\n",
    "                \n",
    "                # Filter objects not similar to images\n",
    "                pieces_features = filter_pieces(STATSDIR, pieces_features, sigma)\n",
    "                save_path = os.path.join(PRED_TESTDIR, f\"{image_file.split('.')[0]}.png\")\n",
    "                \n",
    "                if len(pieces_features) != 0:\n",
    "                    for piece in pieces_features: \n",
    "                        # Get data\n",
    "                        center = piece['centroid']\n",
    "                        radius = piece['radius']\n",
    "                        # Transform pixel on warped image back to original image\n",
    "                        new_pixel = np.dot(np.linalg.inv(M), np.array([[center[0]], [center[1]], [1]]))\n",
    "                        center = [int(new_pixel[0][0]/new_pixel[2][0]), int(new_pixel[1][0]/new_pixel[2][0])]\n",
    "                        \n",
    "                        # Get pixel depth \n",
    "                        pixel_depth = depth[center[1], center[0]]\n",
    "            \n",
    "                        x_wc = center[0]\n",
    "                        y_wc = center[1]\n",
    "                        z_wc = pixel_depth \n",
    "                        \n",
    "                        # Prepare input for the MLP model\n",
    "                        input_mlp_raw = np.array([[x_wc, y_wc, z_wc]])\n",
    "                        input_mlp_scaled = scaler_X.transform(input_mlp_raw)\n",
    "                        input_mlp = torch.tensor(input_mlp_scaled, dtype=torch.float32)\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            output_mlp = model_mlp(input_mlp)\n",
    "                        output_mlp_unscaled = scaler_y.inverse_transform(output_mlp.numpy().reshape(1, -1)).squeeze()\n",
    "                        x_pred, y_pred, z_pred = output_mlp_unscaled\n",
    "\n",
    "                        x_gt, y_gt = labels_gt[0], labels_gt[1]\n",
    "                        \n",
    "                        # Save the differences\n",
    "                        differences.append((x_gt - x_pred, y_gt - y_pred))\n",
    "                        r_value_pointwise = math.sqrt((x_gt - x_pred)**2 + (y_gt - y_pred)**2)\n",
    "                        c = corruption_function_map[corruption]\n",
    "                        s = severity\n",
    "                        pointwise_result.append([sigma, c, s, r_value_pointwise])\n",
    "                        \n",
    "                else:\n",
    "                    NON_DETECTED += 1\n",
    "            \n",
    "            errors_np = np.array(differences)\n",
    "            if len(errors_np) != 0:     \n",
    "                r_values = np.sqrt(np.sum(errors_np**2, axis=1))\n",
    "\n",
    "                # Calculate mean and standard deviation of errors\n",
    "                mean_r = np.mean(r_values)\n",
    "                std_r = np.std(r_values)\n",
    "\n",
    "                percentage = (1 - (NON_DETECTED / TOTAL_PIECES)) * 100\n",
    "                c = corruption_function_map[corruption]\n",
    "                s = severity\n",
    "                \n",
    "                # Save results\n",
    "                results.append([sigma, c, s, mean_r, std_r, percentage])\n",
    "            else:\n",
    "                s = severity\n",
    "                c = corruption_function_map[corruption]\n",
    "                percentage = (1 - (NON_DETECTED / TOTAL_PIECES)) * 100\n",
    "                results.append([sigma, c, s, None, None, percentage])\n",
    "\n",
    "# Create a DataFrame for pointwise results and save it to a CSV file\n",
    "df_pointwise = pd.DataFrame(pointwise_result, columns=['sigma', 'corruption_name', 'severity', 'error'])\n",
    "df_pointwise.to_csv(os.path.join(SAVEFILE, 'results_pointwise_approach2.csv'), index=False)\n",
    "\n",
    "# Create a DataFrame for overall results and save it to a CSV file\n",
    "df = pd.DataFrame(results, columns=['sigma', 'corruption_name', 'severity', 'mean_error', 'std_error', '%detected'])\n",
    "df.to_csv(os.path.join(SAVEFILE, 'results_approach2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af41bca",
   "metadata": {},
   "source": [
    "#### CSV 2 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "data_pointwise = pd.read_csv(FILE_PATH_POINTWISE)\n",
    "\n",
    "# Separate the data into blocks based on unique values of sigma\n",
    "blocks = {sigma: data[data['sigma'] == sigma] for sigma in data['sigma'].unique()}\n",
    "# Separate the pointwise data into blocks based on unique values of sigma\n",
    "blocks_pointwise = {sigma: data_pointwise[data_pointwise['sigma'] == sigma] for sigma in data_pointwise['sigma'].unique()}\n",
    "\n",
    "# Define a list of sigma values to iterate over\n",
    "sigma_list = list(range(1, 10, 2))\n",
    "for i in range(len(blocks)):\n",
    "    sigma = sigma_list[i]\n",
    "\n",
    "    # Create a summary to check the number of unique corruption names and the number of unique severities within each corruption name for each block\n",
    "    block_example = blocks[sigma]\n",
    "\n",
    "    # Create enhanced x-axis labels without the extra 's' prefix\n",
    "    corruption_names = list(corruption_function_map.values())\n",
    "    severity_levels = [f's{i}' for i in range(1, 6)]\n",
    "\n",
    "    # Calculate values for the histogram of percentage detected\n",
    "    data_for_histogram = []\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            subset = block_example[(block_example['corruption_name'] == corruption_name) & (block_example['severity'] == severity)]\n",
    "            if not subset.empty:\n",
    "                detected_value = subset['%detected'].values[0]\n",
    "                data_for_histogram.append(detected_value)\n",
    "            else:\n",
    "                data_for_histogram.append(0)\n",
    "\n",
    "    # Generate colors for each bar in the histogram\n",
    "    bar_colors = []\n",
    "    for corruption_name in corruption_names:\n",
    "        bar_colors.extend([colors[corruption_name]] * len(severity_levels))\n",
    "\n",
    "    # Create the histogram plot\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    y_values_detected = np.array(data_for_histogram)\n",
    "\n",
    "    # Generate the histogram with colors and adjust margins\n",
    "    bar_width = 0.8  # Adjust bar width to leave space between blocks\n",
    "    positions = np.arange(len(y_values_detected)) * 1.1  # Adjust positions to leave space between blocks\n",
    "\n",
    "    plt.bar(positions, y_values_detected, color=bar_colors, width=bar_width)\n",
    "\n",
    "    # Adjust x-axis labels\n",
    "    severity_labels = []\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            severity_labels.append(f'{severity}')\n",
    "\n",
    "    plt.xticks(ticks=positions, labels=severity_labels, rotation=90)\n",
    "\n",
    "    # Adjust y-axis range\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    # Adjust x-axis range to occupy the entire plot\n",
    "    plt.xlim(-0.5, positions[-1] + 0.5)\n",
    "\n",
    "    # Add legend to identify colors\n",
    "    legend_labels = [f'{corruption_function_map[c]} = {c}' for c in corruption_function_map]\n",
    "    handles = [plt.Line2D([0], [0], color=colors[corruption_function_map[c]], lw=4) for c in corruption_function_map]\n",
    "\n",
    "    plt.legend(handles, legend_labels, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Add y-axis label and plot title\n",
    "    plt.ylabel('Detected Percentage')\n",
    "    plt.title(f'Detected Percentage vs Severity and Corruption Name for Sigma = {sigma}')\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    # Save the plot instead of displaying it\n",
    "    plt.savefig(f'{SAVEFOLDER}histogram_sigma_{sigma}_approach2.png')\n",
    "    plt.close()\n",
    "\n",
    "# Repeat the process for pointwise data\n",
    "for i in range(len(blocks_pointwise)):\n",
    "    sigma = sigma_list[i]\n",
    "\n",
    "    # Create a summary to check the number of unique corruption names and the number of unique severities within each corruption name for each block\n",
    "    block_example = blocks_pointwise[sigma]\n",
    "\n",
    "    # Calculate values for the boxplot using percentiles\n",
    "    data_for_boxplot = []\n",
    "    corruption_names = list(corruption_function_map.values())\n",
    "    severity_levels = [f's{i}' for i in range(1, 6)]\n",
    "\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            subset = block_example[(block_example['corruption_name'] == corruption_name) & (block_example['severity'] == severity)]\n",
    "            if not subset.empty:\n",
    "                percentiles = np.percentile(subset['error'], [25, 50, 75])\n",
    "                min_val = subset['error'].min()\n",
    "                max_val = subset['error'].max()\n",
    "                data_for_boxplot.append([min_val, percentiles[0], percentiles[1], percentiles[2], max_val])\n",
    "            else:\n",
    "                data_for_boxplot.append([np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "\n",
    "    # Generate colors for each box in the boxplot\n",
    "    box_colors = []\n",
    "    for corruption_name in corruption_names:\n",
    "        box_colors.extend([colors[corruption_name]] * len(severity_levels))\n",
    "\n",
    "    # Create the boxplot\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    box = plt.boxplot(data_for_boxplot, vert=True, patch_artist=True, whis=[0, 100])\n",
    "\n",
    "    # Apply colors to each box in the boxplot\n",
    "    for patch, color in zip(box['boxes'], box_colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    # Adjust x-axis labels\n",
    "    severity_labels = []\n",
    "    for corruption_name in corruption_names:\n",
    "        for severity in severity_levels:\n",
    "            severity_labels.append(f'{severity}')\n",
    "\n",
    "    plt.xticks(ticks=np.arange(1, len(severity_labels) + 1), labels=severity_labels, rotation=90)\n",
    "\n",
    "    # Add legend to identify colors\n",
    "    legend_labels = [f'{corruption_function_map[c]} = {c}' for c in corruption_function_map]\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, color=colors[corruption_function_map[c]]) for c in corruption_function_map]\n",
    "\n",
    "    plt.legend(handles, legend_labels, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.ylabel('Piece picking uncertainty (mm)')\n",
    "    plt.title(f'Boxplot of Picking uncertainty (mm) vs Severity of Corruption Name for Sigma = {sigma}')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Adjust y-axis limit\n",
    "    plt.ylim(0, 10)\n",
    "    plt.savefig(f'{SAVEFOLDER}boxplot_sigma_{sigma}_approach2.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
